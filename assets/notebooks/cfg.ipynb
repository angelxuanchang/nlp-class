{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import CFG, PCFG\n",
    "from nltk.parse import pchart\n",
    "import sys, re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_comment(s):\n",
    "    \"\"\"Remove comments from a string containing nltk CFG\"\"\"\n",
    "    return re.sub(r'#.*?$', \"\", s, flags=re.MULTILINE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(N (N (N (N natural) (N language)) (N learning)) (N course))\n",
      "(N (N (N natural) (N (N language) (N learning))) (N course))\n",
      "(N (N natural) (N (N (N language) (N learning)) (N course)))\n",
      "(N (N natural) (N (N language) (N (N learning) (N course))))\n",
      "(N (N (N natural) (N language)) (N (N learning) (N course)))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Start: N\n",
      "Productions: [N -> N N, N -> 'natural', N -> 'language', N -> 'learning', N -> 'course']\n"
     ]
    }
   ],
   "source": [
    "grammar = CFG.fromstring(\"\"\"\n",
    "N -> N N | 'natural' | 'language' | 'learning' | 'course'\n",
    "\"\"\")\n",
    "\n",
    "inp = 'natural language learning course'\n",
    "print(\"Start:\", grammar.start(), file=sys.stderr)\n",
    "print(\"Productions:\", grammar.productions(), file=sys.stderr)\n",
    "parser = nltk.ChartParser(grammar)\n",
    "for tree in parser.parse(inp.split()):\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "N -> N N [0.2] \n",
      "N -> 'natural' [0.2] \n",
      "N -> 'language' [0.2] \n",
      "N -> 'learning' [0.2]\n",
      "N -> 'course' [0.2]\n",
      "\n",
      "1.2800000000000006e-05\n",
      "(N\n",
      "  (N natural)\n",
      "  (N (N language) (N (N learning) (N course)))) (p=1.28e-05)\n",
      "(N\n",
      "  (N natural)\n",
      "  (N (N (N language) (N learning)) (N course))) (p=1.28e-05)\n",
      "(N\n",
      "  (N (N natural) (N language))\n",
      "  (N (N learning) (N course))) (p=1.28e-05)\n",
      "(N\n",
      "  (N (N natural) (N (N language) (N learning)))\n",
      "  (N course)) (p=1.28e-05)\n",
      "(N\n",
      "  (N (N (N natural) (N language)) (N learning))\n",
      "  (N course)) (p=1.28e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Start: N\n",
      "Productions: [N -> N N [0.2], N -> 'natural' [0.2], N -> 'language' [0.2], N -> 'learning' [0.2], N -> 'course' [0.2]]\n"
     ]
    }
   ],
   "source": [
    "grammar_string = \"\"\"\n",
    "N -> N N [{}] \n",
    "N -> 'natural' [{}] \n",
    "N -> 'language' [{}] \n",
    "N -> 'learning' [{}]\n",
    "N -> 'course' [{}]\n",
    "\"\"\".format(1/5, 1/5, 1/5, 1/5, 1/5)\n",
    "print(grammar_string)\n",
    "\n",
    "# uses N -> N N three times and each of\n",
    "# the words once each and because each\n",
    "# rule has the same probability we can\n",
    "# easily compute the probability of\n",
    "# each parse tree for this PCFG\n",
    "print((1/5)**3 * (1/5)**4)\n",
    "\n",
    "grammar = PCFG.fromstring(grammar_string)\n",
    "\n",
    "inp = 'natural language learning course'\n",
    "print(\"Start:\", grammar.start(), file=sys.stderr)\n",
    "print(\"Productions:\", grammar.productions(), file=sys.stderr)\n",
    "parser = pchart.InsideChartParser(grammar)\n",
    "for tree in parser.parse(inp.split()):\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "N_1_4 -> N_1   N_2_4\n",
      "N_1_4 -> N_1_3 N_4\n",
      "N_1_4 -> N_1_2 N_3_4\n",
      "N_1_2 -> N_1   N_2   \n",
      "N_2_3 -> N_2   N_3   \n",
      "N_3_4 -> N_3   N_4   \n",
      "N_1_3 -> N_1_2 N_3   \n",
      "N_1_3 -> N_1   N_2_3 \n",
      "N_2_4 -> N_2_3 N_4   \n",
      "N_2_4 -> N_2   N_3_4 \n",
      "N_1 -> 'natural' \n",
      "N_2 -> 'language' \n",
      "N_3 -> 'learning'\n",
      "N_4 -> 'course'\n",
      "\n",
      "(N_1_4\n",
      "  (N_1_3 (N_1_2 (N_1 natural) (N_2 language)) (N_3 learning))\n",
      "  (N_4 course))\n",
      "(N_1_4\n",
      "  (N_1_3 (N_1 natural) (N_2_3 (N_2 language) (N_3 learning)))\n",
      "  (N_4 course))\n",
      "(N_1_4\n",
      "  (N_1 natural)\n",
      "  (N_2_4 (N_2_3 (N_2 language) (N_3 learning)) (N_4 course)))\n",
      "(N_1_4\n",
      "  (N_1 natural)\n",
      "  (N_2_4 (N_2 language) (N_3_4 (N_3 learning) (N_4 course))))\n",
      "(N_1_4\n",
      "  (N_1_2 (N_1 natural) (N_2 language))\n",
      "  (N_3_4 (N_3 learning) (N_4 course)))\n"
     ]
    }
   ],
   "source": [
    "grammar_string = \"\"\"\n",
    "N_1_4 -> N_1   N_2_4\n",
    "N_1_4 -> N_1_3 N_4\n",
    "N_1_4 -> N_1_2 N_3_4\n",
    "N_1_2 -> N_1   N_2   # natural language\n",
    "N_2_3 -> N_2   N_3   # language learning\n",
    "N_3_4 -> N_3   N_4   # learning course\n",
    "N_1_3 -> N_1_2 N_3   # natural language learning\n",
    "N_1_3 -> N_1   N_2_3 # natural language learning\n",
    "N_2_4 -> N_2_3 N_4   # language learning course\n",
    "N_2_4 -> N_2   N_3_4 # language learning course\n",
    "N_1 -> 'natural' \n",
    "N_2 -> 'language' \n",
    "N_3 -> 'learning'\n",
    "N_4 -> 'course'\n",
    "\"\"\"\n",
    "print(strip_comment(grammar_string))\n",
    "grammar = CFG.fromstring(strip_comment(grammar_string))\n",
    "#print(\"Start:\", grammar.start(), file=sys.stderr)\n",
    "#print(\"Productions:\", grammar.productions(), file=sys.stderr)\n",
    "parser = nltk.ChartParser(grammar)\n",
    "inp = 'natural language learning course'.strip()\n",
    "for tree in parser.parse(inp.split()):\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "N_1_4 -> N_1   N_2_4   [0.3333333333333333]\n",
      "N_1_4 -> N_1_3 N_4     [0.3333333333333333]\n",
      "N_1_4 -> N_1_2 N_3_4   [0.3333333333333333]\n",
      "N_1_2 -> N_1   N_2     [1.0] \n",
      "N_2_3 -> N_2   N_3     [1.0] \n",
      "N_3_4 -> N_3   N_4     [1.0] \n",
      "N_1_3 -> N_1_2 N_3     [0.5]  \n",
      "N_1_3 -> N_1   N_2_3   [0.5]  \n",
      "N_2_4 -> N_2_3 N_4     [0.5]  \n",
      "N_2_4 -> N_2   N_3_4   [0.5]  \n",
      "N_1 -> 'natural'       [1.0]\n",
      "N_2 -> 'language'      [1.0]\n",
      "N_3 -> 'learning'      [1.0]\n",
      "N_4 -> 'course'        [1.0]\n",
      "\n",
      "  |[-] . . .| [0:1] 'natural'                        [1.0]\n",
      "  |. [-] . .| [1:2] 'language'                       [1.0]\n",
      "  |. . [-] .| [2:3] 'learning'                       [1.0]\n",
      "  |. . . [-]| [3:4] 'course'                         [1.0]\n",
      "  |. . . [-]| [3:4] 'course'                         [1.0]\n",
      "  |. . . [-]| [3:4] N_4 -> 'course' *                [1.0]\n",
      "  |. . . > .| [3:3] N_4 -> * 'course'                [1.0]\n",
      "  |. . [-] .| [2:3] 'learning'                       [1.0]\n",
      "  |. . [-] .| [2:3] N_3 -> 'learning' *              [1.0]\n",
      "  |. . [-> .| [2:3] N_3_4 -> N_3 * N_4               [1.0]\n",
      "  |. . [---]| [2:4] N_3_4 -> N_3 N_4 *               [1.0]\n",
      "  |. . > . .| [2:2] N_3_4 -> * N_3 N_4               [1.0]\n",
      "  |. . > . .| [2:2] N_3 -> * 'learning'              [1.0]\n",
      "  |. [-] . .| [1:2] 'language'                       [1.0]\n",
      "  |. [-] . .| [1:2] N_2 -> 'language' *              [1.0]\n",
      "  |. [-> . .| [1:2] N_2_3 -> N_2 * N_3               [1.0]\n",
      "  |. [---] .| [1:3] N_2_3 -> N_2 N_3 *               [1.0]\n",
      "  |. > . . .| [1:1] N_2_3 -> * N_2 N_3               [1.0]\n",
      "  |. > . . .| [1:1] N_2 -> * 'language'              [1.0]\n",
      "  |[-] . . .| [0:1] 'natural'                        [1.0]\n",
      "  |[-] . . .| [0:1] N_1 -> 'natural' *               [1.0]\n",
      "  |[-> . . .| [0:1] N_1_2 -> N_1 * N_2               [1.0]\n",
      "  |[---] . .| [0:2] N_1_2 -> N_1 N_2 *               [1.0]\n",
      "  |> . . . .| [0:0] N_1_2 -> * N_1 N_2               [1.0]\n",
      "  |> . . . .| [0:0] N_1 -> * 'natural'               [1.0]\n",
      "  |[---> . .| [0:2] N_1_3 -> N_1_2 * N_3             [0.5]\n",
      "  |[-----] .| [0:3] N_1_3 -> N_1_2 N_3 *             [0.5]\n",
      "  |> . . . .| [0:0] N_1_3 -> * N_1_2 N_3             [0.5]\n",
      "  |[-> . . .| [0:1] N_1_3 -> N_1 * N_2_3             [0.5]\n",
      "  |[-----] .| [0:3] N_1_3 -> N_1 N_2_3 *             [0.5]\n",
      "  |> . . . .| [0:0] N_1_3 -> * N_1 N_2_3             [0.5]\n",
      "  |. [---> .| [1:3] N_2_4 -> N_2_3 * N_4             [0.5]\n",
      "  |. [-----]| [1:4] N_2_4 -> N_2_3 N_4 *             [0.5]\n",
      "  |. > . . .| [1:1] N_2_4 -> * N_2_3 N_4             [0.5]\n",
      "  |. [-> . .| [1:2] N_2_4 -> N_2 * N_3_4             [0.5]\n",
      "  |. [-----]| [1:4] N_2_4 -> N_2 N_3_4 *             [0.5]\n",
      "  |. > . . .| [1:1] N_2_4 -> * N_2 N_3_4             [0.5]\n",
      "  |> . . . .| [0:0] N_1_4 -> * N_1_3 N_4             [0.3333333333333333]\n",
      "  |[---> . .| [0:2] N_1_4 -> N_1_2 * N_3_4           [0.3333333333333333]\n",
      "  |[=======]| [0:4] N_1_4 -> N_1_2 N_3_4 *           [0.3333333333333333]\n",
      "  |> . . . .| [0:0] N_1_4 -> * N_1_2 N_3_4           [0.3333333333333333]\n",
      "  |[-> . . .| [0:1] N_1_4 -> N_1 * N_2_4             [0.3333333333333333]\n",
      "  |> . . . .| [0:0] N_1_4 -> * N_1 N_2_4             [0.3333333333333333]\n",
      "  |[=======]| [0:4] N_1_4 -> N_1 N_2_4 *             [0.16666666666666666]\n",
      "  |[=======]| [0:4] N_1_4 -> N_1 N_2_4 *             [0.16666666666666666]\n",
      "  |[-----> .| [0:3] N_1_4 -> N_1_3 * N_4             [0.16666666666666666]\n",
      "  |[=======]| [0:4] N_1_4 -> N_1_3 N_4 *             [0.16666666666666666]\n",
      "  |[-----> .| [0:3] N_1_4 -> N_1_3 * N_4             [0.16666666666666666]\n",
      "(N_1_4\n",
      "  (N_1_2 (N_1 natural) (N_2 language))\n",
      "  (N_3_4 (N_3 learning) (N_4 course))) (p=0.333333)\n",
      "(N_1_4\n",
      "  (N_1 natural)\n",
      "  (N_2_4\n",
      "    (N_2_3 (N_2 language) (N_3 learning))\n",
      "    (N_4 course))) (p=0.166667)\n",
      "(N_1_4\n",
      "  (N_1 natural)\n",
      "  (N_2_4\n",
      "    (N_2 language)\n",
      "    (N_3_4 (N_3 learning) (N_4 course)))) (p=0.166667)\n",
      "(N_1_4\n",
      "  (N_1_3\n",
      "    (N_1_2 (N_1 natural) (N_2 language))\n",
      "    (N_3 learning))\n",
      "  (N_4 course)) (p=0.166667)\n",
      "(N_1_4\n",
      "  (N_1_3\n",
      "    (N_1 natural)\n",
      "    (N_2_3 (N_2 language) (N_3 learning)))\n",
      "  (N_4 course)) (p=0.166667)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Start: N_1_4\n",
      "Productions: [N_1_4 -> N_1 N_2_4 [0.333333], N_1_4 -> N_1_3 N_4 [0.333333], N_1_4 -> N_1_2 N_3_4 [0.333333], N_1_2 -> N_1 N_2 [1.0], N_2_3 -> N_2 N_3 [1.0], N_3_4 -> N_3 N_4 [1.0], N_1_3 -> N_1_2 N_3 [0.5], N_1_3 -> N_1 N_2_3 [0.5], N_2_4 -> N_2_3 N_4 [0.5], N_2_4 -> N_2 N_3_4 [0.5], N_1 -> 'natural' [1.0], N_2 -> 'language' [1.0], N_3 -> 'learning' [1.0], N_4 -> 'course' [1.0]]\n"
     ]
    }
   ],
   "source": [
    "# write down the probabilities as fractions over \n",
    "# the possible choices for each non-terminal in\n",
    "# the lhs which has multiple possible rhs expansions\n",
    "N_1_4_probs = [1/3, 1/3, 1/3]\n",
    "N_1_3_probs = [1/2, 1/2]\n",
    "N_2_4_probs = [1/2, 1/2]\n",
    "\n",
    "grammar_string = \"\"\"\n",
    "N_1_4 -> N_1   N_2_4   [{}]\n",
    "N_1_4 -> N_1_3 N_4     [{}]\n",
    "N_1_4 -> N_1_2 N_3_4   [{}]\n",
    "N_1_2 -> N_1   N_2     [1.0] # natural language\n",
    "N_2_3 -> N_2   N_3     [1.0] # language learning\n",
    "N_3_4 -> N_3   N_4     [1.0] # learning course\n",
    "N_1_3 -> N_1_2 N_3     [{}]  # natural language learning\n",
    "N_1_3 -> N_1   N_2_3   [{}]  # natural language learning\n",
    "N_2_4 -> N_2_3 N_4     [{}]  # language learning course\n",
    "N_2_4 -> N_2   N_3_4   [{}]  # language learning course\n",
    "N_1 -> 'natural'       [1.0]\n",
    "N_2 -> 'language'      [1.0]\n",
    "N_3 -> 'learning'      [1.0]\n",
    "N_4 -> 'course'        [1.0]\n",
    "\"\"\".format(*N_1_4_probs, *N_1_3_probs, *N_2_4_probs) \n",
    "# using * the lists are flattened and we get (1/3, 1/3, 1/3, 1/2, 1/2, 1/2, 1/2)\n",
    "\n",
    "print(strip_comment(grammar_string))\n",
    "grammar = PCFG.fromstring(strip_comment(grammar_string))\n",
    "print(\"Start:\", grammar.start(), file=sys.stderr)\n",
    "print(\"Productions:\", grammar.productions(), file=sys.stderr)\n",
    "parser = pchart.InsideChartParser(grammar)\n",
    "parser.trace(3)\n",
    "inp = 'natural language learning course'.strip()\n",
    "for tree in parser.parse(inp.split()):\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_1_4_probs = [1/30, 28/30, 1/30]\n",
    "N_1_3_probs = [19/20, 1/20]\n",
    "N_2_4_probs = [1/2, 1/2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
