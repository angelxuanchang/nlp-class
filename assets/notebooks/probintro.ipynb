{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Probability Models for NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Anoop Sarkar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This is a brief, interactive guide to probability theory. It provides an  introduction to the basic concepts we will rely on to build models of uncertainty in natural language processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import division\n",
    "import numpy\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "import nltk\n",
    "import random\n",
    "import json\n",
    "from operator import itemgetter\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## NLTK as a data source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "We will use the [Python Natural Language Toolkit](http://nltk.org) as a source of data. \n",
    "First step, let us load up some text data from Lewis Carroll's \"Alice's Adventures in Wonderland\" and print out the first few words from the book. \n",
    "Notice that NLTK has already split up all the text in that book into tokens we can use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[', 'Alice', \"'\", 's', 'Adventures', 'in', 'Wonderland', 'by', 'Lewis', 'Carroll', '1865', ']', 'CHAPTER', 'I', '.', 'Down', 'the', 'Rabbit', '-', 'Hole', 'Alice', 'was', 'beginning', 'to', 'get', 'very', 'tired', 'of', 'sitting', 'by', 'her', 'sister', 'on', 'the', 'bank', ',', 'and', 'of', 'having', 'nothing', 'to', 'do', ':', 'once', 'or', 'twice', 'she', 'had', 'peeped', 'into', 'the', 'book', 'her', 'sister', 'was', 'reading', ',', 'but', 'it', 'had', 'no', 'pictures', 'or', 'conversations', 'in', 'it', ',', \"'\", 'and', 'what', 'is', 'the', 'use', 'of', 'a', 'book', \",'\", 'thought', 'Alice', \"'\", 'without', 'pictures', 'or', 'conversation', \"?'\"]\n"
     ]
    }
   ],
   "source": [
    "from itertools import islice\n",
    "# print the first few words from Lewis Carroll's \"Alice's Adventures in Wonderland\"\n",
    "# islice takes the first n elements from the iterator without building the whole list of words for the document\n",
    "print([w for w in islice(nltk.corpus.gutenberg.words('carroll-alice.txt'),85)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Probability Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Sampling without replacement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "For now, let us view the text as a bag of letters taken from the English alphabet. By a \"bag\" of letters, we mean that we take this book to consist of unordered letter tokens, and so the ordering or the sequence in which the letters occur is ignored for now.\n",
    "\n",
    "To create a new sample, we simply choose a letter at random and add it to our sample. We do not remove the letter from our list because we are *sampling with replacement*, and repeatedly sample again and again until we reach a sample of a desired size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The class `lettersample` below produces a sample of a desired size `num`. If a letter appears more often in the original list of letters from which we are sampling, then that letter will appear proportionally more often in our sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# sample letters from a document with replacement\n",
    "class lettersample:\n",
    "    \n",
    "    def __init__(self, num):\n",
    "        self.corpus = [c.lower() for sent in nltk.corpus.gutenberg.sents('carroll-alice.txt') for c in ''.join(sent)]\n",
    "        self.sample = [random.choice(self.corpus) for i in range(num)]\n",
    "\n",
    "    # __str__ creates a printable representation of the object\n",
    "    def __str__(self):\n",
    "        return ''.join(self.sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ntredl\n"
     ]
    }
   ],
   "source": [
    "s = lettersample(6)\n",
    "print((''.join(s.sample))) # print the sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Creating a probability distribution from a sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "When we have a sample, we can count how many times each letter $c$ occured in the sample. Let us call this the frequency of $c$ or $n(c)$.\n",
    "\n",
    "For example, if we have a random sample of size 6: $eeaaei$ then $n(e) = 3$, $n(a) = 2$, $n(i) = 1$. Notice that $\\sum_{c} n(c) = n(e) + n(a) + n(i) = 6$ which is the sample size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"t\": 1,\n",
      "    \"y\": 1,\n",
      "    \"b\": 1,\n",
      "    \"i\": 1,\n",
      "    \"r\": 1,\n",
      "    \"o\": 1\n",
      "}\n",
      "sample size: 6\n"
     ]
    }
   ],
   "source": [
    "s = lettersample(6)\n",
    "n = defaultdict(int)\n",
    "for c in s.sample:\n",
    "    n[c] += 1\n",
    "print((json.dumps(n, indent=4)))\n",
    "print((\"sample size:\", sum(n.values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "\n",
    "We can create probability distribution over the set of letters (the alphabet) by simply summing over the number of times we observed a letter in the sample and dividing by the number of times we observed all the letters (which is the same as the size of the sample). If $n(c)$ is the count of letter $c$ then we can write down the probability of any letter $c$ as \n",
    "\n",
    "$$ P(c) = \\frac{n(c)}{\\sum_{c'} n(c')} $$\n",
    "\n",
    "As we just observed in the above example, $\\sum_{c'} n(c')$ is equal to the sample size.\n",
    "\n",
    "$P(c)$ is called the unigram letter probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"t\": 0.16666666666666666,\n",
      "    \"y\": 0.16666666666666666,\n",
      "    \"b\": 0.16666666666666666,\n",
      "    \"i\": 0.16666666666666666,\n",
      "    \"r\": 0.16666666666666666,\n",
      "    \"o\": 0.16666666666666666\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "total = sum(n.values())\n",
    "prob = { c: (n[c] / total) for c in list(n.keys()) }\n",
    "print((json.dumps(prob, indent=4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Probability distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A probability is a real number between zero and one. A probability distribution is created over a set where each element in the set has a probability and the sum over all elements in this set must sum to one. So if our set was called $S$ then this condition on the probability distribution $P$ over elements of set $S$ is written as \n",
    "\n",
    "$$ \\sum_{c \\in S} P(c) = 1.0 $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print((format(sum(prob.values()), '.12g')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read more about [floating point arithmetic](https://docs.python.org/3/tutorial/floatingpoint.html) to understand why `format` was used above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* $S$ is the _sample space_\n",
    "* A random variable $X$ is a function from $S$ to disjoint subset of $S$\n",
    "\n",
    "For example:\n",
    "\n",
    "$S = \\{ a, b, c, \\ldots z \\}$\n",
    "\n",
    "$X(c) = c$ where $c \\in S$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Finding the argmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Often we wish to compute the argmax using a probability distribution. The argmax function returns the element that has the highest probability. $$\\hat{c} = \\arg\\max_c P(c)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t 0.16666666666666666\n"
     ]
    }
   ],
   "source": [
    "def P(c):\n",
    "    return prob[c]\n",
    "# the character with the highest probability is given by argmax_c P(c)\n",
    "argmax_char = max(list(n.keys()), key=P)\n",
    "print((argmax_char, P(argmax_char)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Sample size and probability estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that larger samples result in a more accurate measurement of the probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def sample_dist(fdist):\n",
    "    return([ (sample, fdist[sample]) for sample in fdist ])\n",
    "\n",
    "def vertical_bars(sample_dist):\n",
    "    samples = list(map(itemgetter(0), sample_dist))\n",
    "    freqs = list(map(itemgetter(1), sample_dist))\n",
    "    # samples = fdist.samples()\n",
    "    # freqs = [ fdist[sample] for sample in samples ]\n",
    "    labels = [str(s) for s in samples]\n",
    "    fig, ax1 = plt.subplots(figsize=(15, 10))\n",
    "    pos = numpy.arange(len(labels))\n",
    "    ax1.bar(list(pos), list(freqs), facecolor='#9999ff', edgecolor='white')\n",
    "    font = matplotlib.font_manager.FontProperties()\n",
    "    font.set_size('x-large')\n",
    "    for x,y in zip(pos,freqs):\n",
    "        ax1.text(x+0.4, y+0.05, '%s' % labels[x], fontproperties=font, ha='center', va= 'bottom')\n",
    "    plt.tick_params(\\\n",
    "        axis='x',          # changes apply to the x-axis\n",
    "        which='both',      # both major and minor ticks are affected\n",
    "        bottom=False,      # ticks along the bottom edge are off\n",
    "        top=False,         # ticks along the top edge are off\n",
    "        labelbottom=False) # labels along the bottom edge are off\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let us plot the probability distribution over letters when the sample size is 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fem,ttaeergncuileo?tu'gthoaed'eiaegelda.tewponfeniauariiuyaetttea'yaoawniibrhusptreesicnhlipnw\"cknth\n"
     ]
    }
   ],
   "source": [
    "sample1 = lettersample(100)\n",
    "print((''.join(sample1.sample[:100]))) # print the first 100 chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('f', 2), ('e', 14), ('m', 1), (',', 1), ('t', 10), ('a', 10), ('r', 4), ('g', 3), ('n', 7), ('c', 3), ('u', 5), ('i', 9), ('l', 3), ('o', 4), ('?', 1), (\"'\", 3), ('h', 4), ('d', 2), ('.', 1), ('w', 3), ('p', 3), ('y', 2), ('b', 1), ('s', 2), ('\"', 1), ('k', 1)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fdist1 = nltk.probability.FreqDist(sample1.sample)\n",
    "print((sample_dist(fdist1)))\n",
    "s = sorted(sample_dist(fdist1), reverse=True, key=itemgetter(1))\n",
    "vertical_bars(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now let us take a larger sample of 100,000 characters. The plot of the probability distribution now shows a more accurate likelihood of each character in English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cldiasatneaveiybagosparnfouuegttestuo,otioatteuoneihyxoeeee,w.itt':ltiesllvaamshpwhhbdaeyys'ttnkbe's\n"
     ]
    }
   ],
   "source": [
    "sample2 = lettersample(100000)\n",
    "print((''.join(sample2.sample[:100]))) # print the first 100 chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fdist2 = nltk.probability.FreqDist(sample2.sample)\n",
    "vertical_bars(sorted(sample_dist(fdist2), reverse=True, key=itemgetter(1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Random Probability Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Now let us compare a character sample taken from a real English document with a totally random assignment of probabilities to English characters. The difference in the distribution is not just in the assignment of probabilities to individual characters, but the shape of the distribution is altogether different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3AAAAI3CAYAAADawLm3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAFWtJREFUeJzt3V+oZedZx/HfY5ehtv5J2hxCTIoTMFSKIC1DrRREGi/SKiYXpbRIjSWyb6xWK9joTW9bEGsFqWya6gilf4iFBBElxBbxwuCkLfZPLB0iaROS5oi2il7Uja8Xs4tjMslMzzrrnPOc/fnAcM5eZ+1nvzBXX96116oxRgAAADj5vue4FwAAAMDVEXAAAABNCDgAAIAmBBwAAEATAg4AAKAJAQcAANCEgAMAAGhCwAEAADQh4AAAAJqYjnsBSXL99dePM2fOHPcyAAAAjsUjjzzyL2OMvSuddyIC7syZMzl//vxxLwMAAOBYVNXjV3OeSygBAACaEHAAAABNCDgAAIAmBBwAAEATAg4AAKAJAQcAANCEgAMAAGhCwAEAADQh4AAAAJoQcAAAAE0IOAAAgCYEHAAAQBNXDLiq+khVPVNVX7zk2Muq6sGq+ur253Xb41VVf1hVF6rqH6vqNUsuHgAAYJdczQ7cnya5/VnH7kny0Bjj1iQPbV8nyRuT3Lr9t0ryocNZJgAAAFcMuDHG3yb512cdviPJue3v55LcecnxPxsX/X2Sa6vqxsNaLAAAwC476HfgbhhjPLX9/ekkN2x/vynJ1y8574ntseeoqlVVna+q8/v7+wdcBgAAwO6YfROTMcZIMg7wvvUY4+wY4+ze3t7cZQAAAJx6Bw24b3zn0sjtz2e2x59M8opLzrt5ewwAAICZDhpwDyS5a/v7XUnuv+T4L23vRvm6JN+65FJLAAAAZpiudEJVfSzJzyS5vqqeSPLeJO9L8smqujvJ40nesj39L5O8KcmFJP+V5B0LrBkAAGAnXTHgxhhve54/3XaZc0eSX527KAAAAJ5r9k1MAAAAOBoCDgAAoAkBBwAA0ISAewGbTe/5AADA6XLFm5jssmlK1uvl5q9Wy80GAABOHztwAAAATQg4AACAJgQcAABAEwIOAACgCQEHAADQhIADAABoQsABAAA0IeAAAACaEHAAAABNCDgAAIAmBBwAAEATAu4E2mx6zgYAAJY1HfcCeK5pStbrZWavVsvMBQAAlmcHDgAAoAkBBwAA0ISAAwAAaELAAQAANCHgAAAAmhBwAAAATQg4AACAJgQcAABAEwIOAACgCQEHAADQhIADAABoQsABAAA0IeAAAACaEHAAAABNCDgAAIAmBBwAAEATAg4AAKAJAQcAANCEgAMAAGhCwAEAADQh4EiSbDa95wMAwC6YjnsBnAzTlKzXy81frZabDQAAu8IOHAAAQBMCDgAAoAkBBwAA0ISAAwAAaELAAQAANCHgAAAAmhBwAAAATQg4AACAJgQcAABAEwIOAACgCQEHAADQhIADAABoQsABAAA0IeAAAACaEHAAAABNCDgAAIAmBBwAAEATAg4AAKAJAQcAANCEgAMAAGhCwAEAADQh4AAAAJoQcAAAAE0IOAAAgCYEHAAAQBMCDgAAoAkBBwAA0ISAAwAAaELAAQAANCHgAAAAmhBwAAAATQg4AACAJgQcAABAEwIOAACgCQEHAADQhIADAABoQsABAAA0IeAAAACaEHAAAABNCDgAAIAmBBwAAEATAg4AAKAJAQcAANCEgAMAAGhCwAEAADQh4AAAAJoQcAAAAE0IOAAAgCYEHAAAQBMCDgAAoAkBBwAA0ISAAwAAaELAAQAANCHgAAAAmhBwAAAATQg4AACAJmYFXFX9ZlV9qaq+WFUfq6oXV9UtVfVwVV2oqk9U1TWHtVgAAIBdduCAq6qbkvx6krNjjB9P8qIkb03y/iQfGGP8aJJ/S3L3YSwUAABg1829hHJK8n1VNSV5SZKnkrwhyX3bv59LcufMzwAAACAzAm6M8WSS30vytVwMt28leSTJN8cYm+1pTyS5ae4iAQAAmHcJ5XVJ7khyS5IfTvLSJLd/F+9fVdX5qjq/v79/0GUAAADsjDmXUP5skn8eY+yPMf47yaeSvD7JtdtLKpPk5iRPXu7NY4z1GOPsGOPs3t7ejGUAAADshjkB97Ukr6uql1RVJbktyZeTfDrJm7fn3JXk/nlLBAAAIJn3HbiHc/FmJZ9N8oXtrHWS9yR5d1VdSPLyJPcewjoBAAB23nTlU57fGOO9Sd77rMOPJXntnLkAAAA819zHCAAAAHBEBBwAAEATAg4AAKAJAQcAANCEgAMAAGhCwAEAADQh4AAAAJoQcAAAAE0IOAAAgCYEHAAAQBMCDgAAoAkBBwAA0ISAAwAAaELAAQAANCHgAAAAmhBwAAAATQg4AACAJgQcAABAEwIOAACgCQEHAADQhIDjWG02PWcDAMBxmI57Aey2aUrW62Vmr1bLzAUAgONiBw4AAKAJAQcAANCEgAMAAGhCwAEAADQh4AAAAJoQcAAAAE0IOAAAgCYEHAAAQBMCDgAAoAkBBwAA0ISAAwAAaELAAQAANCHgAAAAmhBwAAAATQg4AACAJgQcAABAEwIOAACgCQEHAADQhIADAABoQsABAAA0IeAAAACaEHAAAABNCDgAAIAmBBwAAEATAg4AAKAJAQcAANCEgAMAAGhCwAEAADQh4AAAAJoQcAAAAE0IOAAAgCYEHAAAQBMCDgAAoAkBBwAA0ISAAwAAaELAAQAANCHgAAAAmhBwAAAATQg4AACAJgQcAABAEwIOAACgCQEHAADQhIADAABoQsABAAA0IeAAAACaEHAAAABNCDgAAIAmBBwAAEATAg4AAKAJAQcAANCEgAMAAGhCwAEAADQh4AAAAJoQcAAAAE0IOAAAgCYEHAAAQBMCjp2z2fSeDwDA7pqOewFw1KYpWa+Xm79aLTcbAIDdZgcOAACgCQEHAADQhIADAABoQsABAAA0IeAAAACaEHAAAABNCDgAAIAmBBwAAEATAg4AAKAJAQdHZLPpORsAgJNjOu4FwK6YpmS9Xmb2arXMXAAAThY7cHCKLb0zZ+cPAOBo2YGDU2zJXb/Ezh8AwFGzAwcAANCEgAMAAGhCwAEAADQxK+Cq6tqquq+q/qmqHq2qn6qql1XVg1X11e3P6w5rsQAAALts7g7cB5P81Rjjx5L8RJJHk9yT5KExxq1JHtq+BgAAYKYDB1xV/VCSn05yb5KMMb49xvhmkjuSnNuedi7JnXMXCQAAwLwduFuS7Cf5k6r6XFV9uKpemuSGMcZT23OeTnLD3EUCAAAwL+CmJK9J8qExxquT/GeedbnkGGMkGZd7c1Wtqup8VZ3f39+fsQwAAIDdMCfgnkjyxBjj4e3r+3Ix6L5RVTcmyfbnM5d78xhjPcY4O8Y4u7e3N2MZAAAAu+HAATfGeDrJ16vqldtDtyX5cpIHkty1PXZXkvtnrRAAAIAkFy+DnOPXkny0qq5J8liSd+RiFH6yqu5O8niSt8z8DAAAADIz4MYYn09y9jJ/um3OXAAAAJ5r7nPgAAAAOCICDgAAoAkBBwAA0ISAAwAAaELAAQAANCHgAAAAmhBwAAAATQg4AACAJgQcAABAEwIOAACgCQEHAADQhIADDt1m03M2AMBJNx33AoDTZ5qS9XqZ2avVMnMBADqwAwcAANCEgAMAAGhCwAEAADQh4AAAAJoQcAAAAE0IOAAAgCYEHAAAQBMCDgAAoAkBBwAA0ISAAwAAaELAAQAANCHgAAAAmhBwAAAATQg4AACAJgQcAABAEwIOAACgCQEHAADQhIADAABoQsABAAA0IeAAAACaEHAAAABNCDgAAIAmBBwAAEATAg4AAKAJAQcAANCEgAMAAGhCwAEAADQh4AAAAJoQcAAAAE0IOAAAgCYEHAAAQBMCDgAAoAkBB5wKm03v+QAAV2M67gUAHIZpStbr5eavVsvNBgC4WnbgAAAAmhBwAAAATQg4AACAJgQcAABAEwIOAACgCQEHAADQhIADAABoQsABAAA0IeAAAACaEHAAAABNCDgAAIAmBBwAAEATAg4AAKAJAQcAANCEgAMAAGhCwAEAADQh4AAAAJoQcAAAAE0IOAAAgCYEHAAAQBMCDmCGzabnbACgp+m4FwDQ2TQl6/Uys1erZeYCAH3ZgQMAAGhCwAEAADQh4AAAAJoQcAAAAE0IOIBmlr47pbtfAsDJ5S6UAM0seefLxN0vAeAkswMHAADQhIADAABoQsABcFWW/G6c790BwNXxHTgArsqS373zvTsAuDp24AAAAJoQcAAAAE0IOAAAgCYEHAAAQBMCDgAAoAkBBwAA0ISAAwAAaELAAQAANCHgAAAAmhBwAJxYm03v+QBw2KbjXgAAPJ9pStbr5eavVsvNBoAl2IEDAABoQsABAAA0IeAAAACaEHAAAABNCDgAAIAmBBwAAEATAg4AAKCJ2QFXVS+qqs9V1V9sX99SVQ9X1YWq+kRVXTN/mQBwdJZ8wLeHhwMwx2E8yPtdSR5N8oPb1+9P8oExxser6o+T3J3kQ4fwOQBwJJZ8gLiHhwMwx6wduKq6OcnPJfnw9nUleUOS+7annEty55zPAAAA4KK5l1D+QZLfTvI/29cvT/LNMcZ3LhB5IslNl3tjVa2q6nxVnd/f35+5DAAAgNPvwAFXVT+f5JkxxiMHef8YYz3GODvGOLu3t3fQZQAAAOyMOd+Be32SX6iqNyV5cS5+B+6DSa6tqmm7C3dzkifnLxMAAIAD78CNMX5njHHzGONMkrcm+Zsxxi8m+XSSN29PuyvJ/bNXCQAAwCLPgXtPkndX1YVc/E7cvQt8BgAAwM45jMcIZIzxmSSf2f7+WJLXHsZcAAAA/s8SO3AAAAAsQMABAAA0IeAAAACaEHAAAABNCDgAAIAmBBwAAEATAg4AAKAJAQcAANCEgAMAAGhCwAEAADQh4AAAAJoQcAAAAE0IOAAAgCYEHAAAQBMCDgAAoAkBBwAA0ISAAwAAaELAAQAANCHgAAAAmhBwAAAATQg4AACAJgQcAABAEwIOAACgCQEHAADQhIADAABoQsABAAA0IeAAAACaEHAAAABNCDgAAIAmBBwAAEATAg4AAKAJAQcAANCEgAMAAGhCwAEAADQh4AAAAJoQcAAAAE0IOAAAgCYEHAAAQBMCDgAAoAkBBwAA0ISAAwAAaELAAQAANCHgAAAAmhBwAAAATQg4AACAJgQcAABAEwIOAACgCQEHACfAZtN7PgBHYzruBQAAyTQl6/Vy81er5WYDcHTswAEAADQh4ABghy15aaXLNgEOn0soAWCHLXnppss2AQ6fHTgAAIAmBBwAAEATAg4AAKAJAQcAANCEgAMAAGhCwAEAADQh4ACAI7X08+E8fw44zTwHDgA4Uks+ey7x/DngdLMDBwAA0ISAAwAAaELAAQAANCHgAAAAmhBwAAAATQg4AACAJgQcAABAEwIOAACgCQEHAADQhIADAE69zab3fIDvmI57AQAAS5umZL1ebv5qtdxsgEvZgQMAAGhCwAEAADQh4AAAAJoQcAAAAE0IOAAAgCYEHAAAQBMCDgAAoAkBBwAA0ISAAwAAaELAAQAANCHgAAAAmhBwAAAATQg4AACAJgQcAMBCNpve84GTZzruBQAAnFbTlKzXy81frZabDZxMduAAAACaEHAAAABNCDgAAIAmBBwAAEATAg4AAKAJAQcAANCEgAMAAGhCwAEAADQh4AAAAJoQcAAAAE0cOOCq6hVV9emq+nJVfamq3rU9/rKqerCqvrr9ed3hLRcAgBey2fSeD7ywacZ7N0l+a4zx2ar6gSSPVNWDSX45yUNjjPdV1T1J7knynvlLBQDgSqYpWa+Xm79aLTcbuLID78CNMZ4aY3x2+/t/JHk0yU1J7khybnvauSR3zl0kAAAAh/QduKo6k+TVSR5OcsMY46ntn55OcsPzvGdVVeer6vz+/v5hLAMAAOBUmx1wVfX9Sf48yW+MMf790r+NMUaScbn3jTHWY4yzY4yze3t7c5cBAABw6s0KuKr63lyMt4+OMT61PfyNqrpx+/cbkzwzb4kAAJx0bp4CR+PANzGpqkpyb5JHxxi/f8mfHkhyV5L3bX/eP2uFAACceG6eAkdjzl0oX5/k7Um+UFWf3x773VwMt09W1d1JHk/ylnlLBAAAIJkRcGOMv0tSz/Pn2w46FwAAgMs7lLtQAgAAsDwBBwAA0ISAAwAAaELAAQAANCHgAAAAmhBwAAAATQg4AACAJgQcAABAEwIOAACgCQEHAADQhIADAABoQsABAAA0IeAAAACaEHAAAABNCDgAAIAmBBwAAEATAg4AAKAJAQcAANCEgAMAAGhCwAEAADQh4AAAAJoQcAAAAE0IOAAAgCYEHAAAQBMCDgCAljab3vPhIKbjXgAAABzENCXr9XLzV6vlZsNB2YEDAABoQsABAAA0IeAAAACaEHAAAABNCDgAAIAmBBwAAEATAg4AAKAJAQcAANCEgAMAAGhCwAEAADQh4AAAAJoQcAAAAE0IOAAAgCYEHAAAQBMCDgAAoAkBBwAA0ISAAwAAaELAAQAANCHgAAAAmhBwAAAATQg4AACAJgQcAABAEwIOAACgCQEHAADQhIADAABoQsABAAA0IeAAAOC7sNn0nk9v03EvAAAAOpmmZL1ebv5q9dxjm83Fz13K0vM5PP6bAADghDuOaORkcgklAABAEwIOAACgCQEHAADQhIADAABoQsABAAA0IeAAAACaEHAAAABNCDgAAIAmBBwAAEATAg4AAKAJAQcAANCEgAMAAGhCwAEAADQh4AAAAJoQcAAAAE0IOAAAgCYEHAAAQBMCDgAAoAkBBwAA0ISAAwAAaELAAQAANCHgAAAAmhBwAAAATQg4AADgsjab3vNPo+m4FwAAAJxM05Ss18vNX62Wm31a2YEDAABoQsABAAA0IeAAAACaEHAAAABNCDgAAIAmBBwAAEATAg4AADgxPHvuhXkOHAAAcGJ49twLswMHAADQhIADAABoQsABAAA0IeAAAACaEHAAAABNCDgAAIAmBBwAAEATAg4AAKCJRQKuqm6vqq9U1YWqumeJzwAAANg1hx5wVfWiJH+U5I1JXpXkbVX1qsP+HAAAgF2zxA7ca5NcGGM8Nsb4dpKPJ7ljgc8BAADYKUsE3E1Jvn7J6ye2xwAAAJihxhiHO7DqzUluH2P8yvb125P85Bjjnc86b5VktX35yiRfOdSFAAAA9PEjY4y9K500LfDBTyZ5xSWvb94e+3/GGOsk6wU+HwAA4FRa4hLKf0hya1XdUlXXJHlrkgcW+BwAAICdcug7cGOMTVW9M8lfJ3lRko+MMb502J8DAACwaw79O3AAAAAsY5EHeQMAAHD4BBwAAEATAg4AAKAJAQcAANCEgAMAAGhCwAEAADQh4AAAAJoQcAAAAE38L5kEglSztq3kAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import string\n",
    "import numpy\n",
    "# set up a random probability distribution over lowercase ASCII characters\n",
    "counts = [ 100*numpy.random.random() for c in string.ascii_lowercase ]\n",
    "sample_dist = [ (c, counts[i]) for (i,c) in enumerate(string.ascii_lowercase) ]\n",
    "vertical_bars(sorted(sample_dist, reverse=True, key=itemgetter(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08397712943230941\n",
      "0.021075338844369084\n"
     ]
    }
   ],
   "source": [
    "total = sum(counts)\n",
    "# the following is a dictionary comprehension\n",
    "prob = { c: (counts[i] / total) for (i,c) in enumerate(string.ascii_lowercase) }\n",
    "print((prob['e']))\n",
    "print((prob['z']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Joint Probability Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# sample letter bigrams from a document with replacement\n",
    "class bigramsample:\n",
    "    \n",
    "    def __init__(self, num):\n",
    "        self.corpus = [c.lower() for sent in nltk.corpus.gutenberg.sents('carroll-alice.txt') for c in ''.join(sent)]\n",
    "        self.bigrams = [ tuple(self.corpus[i:i+2]) for i in range(len(self.corpus)-1) ]\n",
    "        self.sample = [random.choice(self.bigrams) for i in range(num)]\n",
    "\n",
    "    # __str__ creates a printable representation of the object\n",
    "    def __str__(self):\n",
    "        return ''.join(self.sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t,o\n",
      ",,'\n",
      "t,e\n",
      "e,m\n",
      "b,o\n",
      "y,c\n",
      "y,i\n",
      "s,a\n",
      "b,u\n",
      "a,l\n"
     ]
    }
   ],
   "source": [
    "b = bigramsample(100)\n",
    "print(('\\n'.join([\"%c,%c\" % (x,y) for (x,y) in b.sample[:10] ]))) # print the first 10 bigrams sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y o: 1\n",
      "a t: 1\n",
      "e b: 1\n",
      "d e: 1\n",
      "y w: 1\n",
      "n i: 1\n",
      "o p: 1\n",
      "s l: 1\n",
      "i d: 1\n",
      "e k: 1\n",
      "sample size: 100\n"
     ]
    }
   ],
   "source": [
    "s = bigramsample(100)\n",
    "n = defaultdict(int)\n",
    "for (x,y) in s.sample:\n",
    "    n[x,y] += 1\n",
    "for (x,y) in list(n.keys())[:10]: # print 10 items from the sample\n",
    "    print((\"%c %c: %d\" % (x, y, n[x,y])))\n",
    "print((\"sample size:\", sum(n.values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Sample space $S = \\{ a, b, c, \\ldots, z \\}^2$\n",
    "\n",
    "Random variable $X(x,y) = x$ and $Y(x,y) = y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y o: 0.010000\n",
      "a t: 0.010000\n",
      "e b: 0.010000\n",
      "d e: 0.010000\n",
      "y w: 0.010000\n",
      "n i: 0.010000\n",
      "o p: 0.010000\n",
      "s l: 0.010000\n",
      "i d: 0.010000\n",
      "e k: 0.010000\n"
     ]
    }
   ],
   "source": [
    "total = sum(n.values())\n",
    "prob = { (x,y): (n[x,y] / total) for (x,y) in list(n.keys()) }\n",
    "for (x,y) in list(prob.keys())[:10]: # print 10 probabilities\n",
    "    print((\"%c %c: %f\" % (x, y, prob[x,y])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Finding the argmax of a joint probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The argmax of a joint probability distribution is the values for the joint random variables that returns the highest _joint_ probability. \n",
    "$$\\hat{x},\\hat{y} = \\arg\\max_{x,y} P(X=x,Y=y)$$\n",
    "Which can be written as:\n",
    "$$\\hat{x},\\hat{y} = \\arg\\max_{x,y} P(x,y)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a i: 0.040000\n"
     ]
    }
   ],
   "source": [
    "def P(key):\n",
    "    (x,y) = key\n",
    "    return prob[x,y]\n",
    "# the character with the highest probability is given by argmax_{x,y} P(x,y)\n",
    "(argmax_x, argmax_y) = max(list(n.keys()), key=P)\n",
    "print(\"%c %c: %f\" % (argmax_x, argmax_y, P((argmax_x,argmax_y))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Marginal Probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "A probability distribution over a subset of variables is a _marginal probability_. We can find the probability value of a particular second character by summing over or _marginalizing out_ the first character probabilities.\n",
    "$$ P(Y=d) = \\sum_{x \\in X} P(X=x, Y=d) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('n', 'i'): 0.01, ('a', 'i'): 0.04, ('r', 'i'): 0.02, ('t', 'i'): 0.02, ('u', 'i'): 0.01}\n",
      "P(Y=i)=0.100000\n"
     ]
    }
   ],
   "source": [
    "marginal = { (x,y) : prob[x,y] for (x,y) in list(prob.keys()) if y == argmax_y }\n",
    "print(marginal)\n",
    "print(\"P(Y=%c)=%f\" % (argmax_y, sum(marginal.values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Expectation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The expectation with respect to a probability $P$ is a weighted average of the values taken by the random variable (taken from the event space ${\\cal E}$) where the weights are given by the probability $P$.\n",
    "\n",
    "$$ E_P[x] = \\sum_{x \\in {\\cal E}} x \\cdot P(x) $$\n",
    "\n",
    "For instance if we collect the word lengths from a natural language corpus and collect the probability of occurrence of each length, we can computed the expected value of word length over all words in the vocabulary ${\\cal V}$.\n",
    "\n",
    "$$ E_p[\\ell] = \\sum_{\\ell = \\textrm{len(x) for } x \\in {\\cal V}} \\ell \\cdot P(\\ell) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book: austen-emma.txt\n",
      "Expected word length: 3.7552682315891226\n",
      "\n",
      "Book: austen-persuasion.txt\n",
      "Expected word length: 3.871031159914843\n",
      "\n",
      "Book: austen-sense.txt\n",
      "Expected word length: 3.881371136350794\n",
      "\n",
      "Book: bible-kjv.txt\n",
      "Expected word length: 3.4478209159613487\n",
      "\n",
      "Book: blake-poems.txt\n",
      "Expected word length: 3.503471390950443\n",
      "\n",
      "Book: bryant-stories.txt\n",
      "Expected word length: 3.5004949336788864\n",
      "\n",
      "Book: burgess-busterbrown.txt\n",
      "Expected word length: 3.5167431313610713\n",
      "\n",
      "Book: carroll-alice.txt\n",
      "Expected word length: 3.4010260920551154\n",
      "\n",
      "Book: chesterton-ball.txt\n",
      "Expected word length: 3.8245907047713303\n",
      "\n",
      "Book: chesterton-brown.txt\n",
      "Expected word length: 3.790804410722379\n",
      "\n",
      "Book: chesterton-thursday.txt\n",
      "Expected word length: 3.774276508748356\n",
      "\n",
      "Book: edgeworth-parents.txt\n",
      "Expected word length: 3.50881265338479\n",
      "\n",
      "Book: melville-moby_dick.txt\n",
      "Expected word length: 3.830411128023649\n",
      "\n",
      "Book: milton-paradise.txt\n",
      "Expected word length: 3.887312161115415\n",
      "\n",
      "Book: shakespeare-caesar.txt\n",
      "Expected word length: 3.444121859636899\n",
      "\n",
      "Book: shakespeare-hamlet.txt\n",
      "Expected word length: 3.4637312633832975\n",
      "\n",
      "Book: shakespeare-macbeth.txt\n",
      "Expected word length: 3.4653414001728606\n",
      "\n",
      "Book: whitman-leaves.txt\n",
      "Expected word length: 3.6962481356895207\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def expectation(dist):\n",
    "    sum = 0.0\n",
    "    for len in dist.freqdist():\n",
    "        sum += len * dist.prob(len)\n",
    "        #print len, dist.prob(len)\n",
    "    return sum\n",
    "        \n",
    "for book in nltk.corpus.gutenberg.fileids():\n",
    "    w_len = [len(w) for w in nltk.corpus.gutenberg.words(book)]\n",
    "    len_fd = nltk.FreqDist(w_len)\n",
    "    len_d = nltk.MLEProbDist(len_fd)\n",
    "    print(\"Book:\", book)\n",
    "    print(\"Expected word length:\", expectation(len_d))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entropy is the expected number of bits needed to represent a probability distribution:\n",
    "\n",
    "$$ H(p) = - E_p[ log_2(p(x)) ] $$\n",
    "\n",
    "Or expanding the definition of expectation:\n",
    "\n",
    "$$ H(p) = - \\sum_{x \\in {\\cal E}} p(x) \\cdot log_2(p(x)) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutual Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book: austen-emma.txt\n",
      "Total MI Score: 3.8394953949098727\n",
      "mrs weston\n",
      "had been\n",
      "frank churchill\n",
      "have been\n",
      "could not\n",
      "miss woodhouse\n",
      "she had\n",
      "any thing\n",
      "she was\n",
      "mrs elton\n",
      "did not\n",
      "miss fairfax\n",
      "jane fairfax\n",
      "miss bates\n",
      "every thing \n",
      "\n",
      "\n",
      "Book: austen-persuasion.txt\n",
      "Total MI Score: 4.323107083650349\n",
      "captain wentworth\n",
      "had been\n",
      "lady russell\n",
      "sir walter\n",
      "she had\n",
      "could not\n",
      "they were\n",
      "have been\n",
      "did not\n",
      "mrs clay\n",
      "mrs smith\n",
      "she was\n",
      "mrs musgrove\n",
      "she could\n",
      "captain benwick \n",
      "\n",
      "\n",
      "Book: austen-sense.txt\n",
      "Total MI Score: 4.070847559161385\n",
      "mrs jennings\n",
      "colonel brandon\n",
      "sir john\n",
      "lady middleton\n",
      "have been\n",
      "mrs dashwood\n",
      "could not\n",
      "did not\n",
      "had been\n",
      "she had\n",
      "her sister\n",
      "they were\n",
      "she was\n",
      "every thing\n",
      "her own \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import math\n",
    "\n",
    "verbose = False\n",
    "reverse_flag = True\n",
    "\n",
    "def collocations(words):\n",
    "  from operator import itemgetter\n",
    "\n",
    "  # Count the words and bigrams\n",
    "  wfd = nltk.FreqDist(words)\n",
    "  pfd = nltk.FreqDist(tuple(words[i:i+2]) for i in range(len(words)-1))\n",
    "\n",
    "  scored = [((w1,w2), mi_score(w1, w2, wfd, pfd)) for w1, w2 in pfd]\n",
    "  total_mi_score = 0.0\n",
    "  for ((w1, w2), score) in scored:\n",
    "    total_mi_score += score\n",
    "  print(\"Total MI Score:\", total_mi_score)\n",
    "  scored.sort(key=itemgetter(1), reverse=reverse_flag)\n",
    "  return list(map(itemgetter(0), scored))\n",
    "\n",
    "def mi_score(word1, word2, wfd, pfd):\n",
    "  wpd = nltk.MLEProbDist(wfd)\n",
    "  ppd = nltk.MLEProbDist(pfd)\n",
    "  px = wpd.prob(word1)\n",
    "  py = wpd.prob(word2)\n",
    "  pxy = ppd.prob( (word1, word2) )\n",
    "  mutual_information_score = pxy * math.log((pxy / (px * py)), 2)\n",
    "  if verbose:\n",
    "    print('mi_score: %s, %s: px=%lf py=%lf pxy=%lf mi_score:%lf' % (word1, word2, px, py, pxy, mutual_information_score))\n",
    "  return mutual_information_score\n",
    "\n",
    "def score(word1, word2, wfd, pfd, power=3):\n",
    "  freq1 = wfd[word1]\n",
    "  freq2 = wfd[word2]\n",
    "  freq12 = pfd[(word1, word2)]\n",
    "  return freq12 ** power / float(freq1 * freq2)\n",
    "\n",
    "austenbooks = ['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt']\n",
    "#austenbooks = ['austen-emma.txt']\n",
    "for book in austenbooks:\n",
    "  words = [ word.lower() for word in nltk.corpus.gutenberg.words(book) if len(word) > 2]\n",
    "  print(\"Book:\", book)\n",
    "  print(\"\\n\".join([w1+' '+w2 for w1, w2 in collocations(words)[:15]]), \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunss.otf');\n",
       "    }\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        font-weight: bold;\n",
       "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunsx.otf');\n",
       "    }\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        font-style: oblique;\n",
       "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunsi.otf');\n",
       "    }\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        font-weight: bold;\n",
       "        font-style: oblique;\n",
       "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunso.otf');\n",
       "    }\n",
       "    div.cell{\n",
       "        width:800px;\n",
       "        font-size: 110%;\n",
       "        margin-left:16% !important;\n",
       "        margin-right:auto;\n",
       "    }\n",
       "    h1 {\n",
       "        font-family: Helvetica, serif;\n",
       "    }\n",
       "    h4{\n",
       "        margin-top:12px;\n",
       "        margin-bottom: 3px;\n",
       "       }\n",
       "    div.text_cell_render{\n",
       "        font-family: Computer Modern, \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;\n",
       "        line-height: 145%;\n",
       "        font-size: 110%;\n",
       "        width:800px;\n",
       "        margin-left:auto;\n",
       "        margin-right:auto;\n",
       "    }\n",
       "    .CodeMirror{\n",
       "            font-family: \"Source Code Pro\", source-code-pro,Consolas, monospace;\n",
       "            font-size: 110%;\n",
       "    }\n",
       "    .prompt{\n",
       "        display: None;\n",
       "    }\n",
       "    .text_cell_render h5 {\n",
       "        font-weight: 300;\n",
       "        font-size: 22pt;\n",
       "        color: #4057A1;\n",
       "        font-style: italic;\n",
       "        margin-bottom: .5em;\n",
       "        margin-top: 0.5em;\n",
       "        display: block;\n",
       "    }\n",
       "    \n",
       "    .warning{\n",
       "        color: rgb( 240, 20, 20 )\n",
       "        }  \n",
       "</style>\n",
       "<script>\n",
       "    MathJax.Hub.Config({\n",
       "                        TeX: {\n",
       "                           extensions: [\"AMSmath.js\"]\n",
       "                           },\n",
       "                tex2jax: {\n",
       "                    inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\n",
       "                    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ]\n",
       "                },\n",
       "                displayAlign: 'center', // Change this to 'center' to center equations.\n",
       "                \"HTML-CSS\": {\n",
       "                    styles: {'.MathJax_Display': {\"margin\": 4}}\n",
       "                }\n",
       "        });\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "\n",
    "def css_styling():\n",
    "    styles = open(\"../css/notebook.css\", \"r\").read()\n",
    "    return HTML(styles)\n",
    "css_styling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def horizontal_bars(fdist):\n",
    "    samples = fdist.samples()\n",
    "    freqs = [ fdist[sample] for sample in samples ]\n",
    "    labels = [\"'\" + str(s) + \"'\" for s in samples]\n",
    "    fig, ax1 = plt.subplots(figsize=(15, 10))\n",
    "    plt.subplots_adjust(left=0.115, right=0.88)\n",
    "    pos = numpy.arange(len(labels))+0.5    # Center bars on the Y-axis ticks\n",
    "    rects = ax1.barh(pos, freqs, align='center', height=0.5, color='m')\n",
    "    ax1.axis([0, fdist[fdist.max()], 0, len(labels)])\n",
    "    pylab.yticks(pos, labels)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
