{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Probability Models for NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Anoop Sarkar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This is a brief, interactive guide to probability theory. It provides an  introduction to the basic concepts we will rely on to build models of uncertainty in natural language processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "import nltk\n",
    "import random\n",
    "import json\n",
    "from operator import itemgetter\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## NLTK as a data source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "We will use the [Python Natural Language Toolkit](http://nltk.org) as a source of data. \n",
    "First step, let us load up some text data from Lewis Carroll's \"Alice's Adventures in Wonderland\" and print out the first few words from the book. \n",
    "Notice that NLTK has already split up all the text in that book into tokens we can use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[', 'Alice', \"'\", 's', 'Adventures', 'in', 'Wonderland', 'by', 'Lewis', 'Carroll', '1865', ']', 'CHAPTER', 'I', '.', 'Down', 'the', 'Rabbit', '-', 'Hole', 'Alice', 'was', 'beginning', 'to', 'get', 'very', 'tired', 'of', 'sitting', 'by', 'her', 'sister', 'on', 'the', 'bank', ',', 'and', 'of', 'having', 'nothing', 'to', 'do', ':', 'once', 'or', 'twice', 'she', 'had', 'peeped', 'into', 'the', 'book', 'her', 'sister', 'was', 'reading', ',', 'but', 'it', 'had', 'no', 'pictures', 'or', 'conversations', 'in', 'it', ',', \"'\", 'and', 'what', 'is', 'the', 'use', 'of', 'a', 'book', \",'\", 'thought', 'Alice', \"'\", 'without', 'pictures', 'or', 'conversation', \"?'\"]\n"
     ]
    }
   ],
   "source": [
    "from itertools import islice\n",
    "# print the first few words from Lewis Carroll's \"Alice's Adventures in Wonderland\"\n",
    "# islice takes the first n elements from the iterator without building the whole list of words for the document\n",
    "print([w for w in islice(nltk.corpus.gutenberg.words('carroll-alice.txt'),85)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Probability Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Sampling without replacement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "For now, let us view the text as a bag of letters taken from the English alphabet. By a \"bag\" of letters, we mean that we take this book to consist of unordered letter tokens, and so the ordering or the sequence in which the letters occur is ignored for now.\n",
    "\n",
    "To create a new sample, we simply choose a letter at random and add it to our sample. We do not remove the letter from our list because we are *sampling with replacement*, and repeatedly sample again and again until we reach a sample of a desired size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The class `lettersample` below produces a sample of a desired size `num`. If a letter appears more often in the original list of letters from which we are sampling, then that letter will appear proportionally more often in our sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# sample letters from a document with replacement\n",
    "class lettersample:\n",
    "    \n",
    "    def __init__(self, num):\n",
    "        self.corpus = [c.lower() for sent in nltk.corpus.gutenberg.sents('carroll-alice.txt') for c in ''.join(sent)]\n",
    "        self.sample = [random.choice(self.corpus) for i in range(num)]\n",
    "\n",
    "    # __str__ creates a printable representation of the object\n",
    "    def __str__(self):\n",
    "        return ''.join(self.sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "todehf\n"
     ]
    }
   ],
   "source": [
    "s = lettersample(6)\n",
    "print(''.join(s.sample)) # print the sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Creating a probability distribution from a sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "When we have a sample, we can count how many times each letter $c$ occured in the sample. Let us call this the frequency of $c$ or $n(c)$.\n",
    "\n",
    "For example, if we have a random sample of size 6: $eeaaei$ then $n(e) = 3$, $n(a) = 2$, $n(i) = 1$. Notice that $\\sum_{c} n(c) = n(e) + n(a) + n(i) = 6$ which is the sample size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"f\": 1,\n",
      "    \"g\": 1,\n",
      "    \"t\": 1,\n",
      "    \"y\": 1,\n",
      "    \".\": 1,\n",
      "    \"h\": 1\n",
      "}\n",
      "sample size: 6\n"
     ]
    }
   ],
   "source": [
    "s = lettersample(6)\n",
    "n = defaultdict(int)\n",
    "for c in s.sample:\n",
    "    n[c] += 1\n",
    "print(json.dumps(n, indent=4))\n",
    "print(\"sample size:\", sum(n.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "\n",
    "We can create probability distribution over the set of letters (the alphabet) by simply summing over the number of times we observed a letter in the sample and dividing by the number of times we observed all the letters (which is the same as the size of the sample). If $n(c)$ is the count of letter $c$ then we can write down the probability of any letter $c$ as \n",
    "\n",
    "$$ P(c) = \\frac{n(c)}{\\sum_{c'} n(c')} $$\n",
    "\n",
    "As we just observed in the above example, $\\sum_{c'} n(c')$ is equal to the sample size.\n",
    "\n",
    "$P(c)$ is called the unigram letter probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"f\": 0.16666666666666666,\n",
      "    \"g\": 0.16666666666666666,\n",
      "    \"t\": 0.16666666666666666,\n",
      "    \"y\": 0.16666666666666666,\n",
      "    \".\": 0.16666666666666666,\n",
      "    \"h\": 0.16666666666666666\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "total = sum(n.values())\n",
    "prob = { c: (n[c] / total) for c in list(n.keys()) }\n",
    "print(json.dumps(prob, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Probability distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A probability is a real number between zero and one. A probability distribution is created over a set where each element in the set has a probability and the sum over all elements in this set must sum to one. So if our set was called $S$ then this condition on the probability distribution $P$ over elements of set $S$ is written as \n",
    "\n",
    "$$ \\sum_{c \\in S} P(c) = 1.0 $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(format(sum(prob.values()), '.1g'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read more about [floating point arithmetic](https://docs.python.org/3/tutorial/floatingpoint.html) to understand why `format` was used above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* $S$ is the _sample space_\n",
    "* A random variable $X$ is a function from $S$ to disjoint subset of $S$\n",
    "\n",
    "For example:\n",
    "\n",
    "$S = \\{ a, b, c, \\ldots z \\}$\n",
    "\n",
    "$X(c) = c$ where $c \\in S$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Finding the argmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Often we wish to compute the argmax using a probability distribution. The argmax function returns the element that has the highest probability. $$\\hat{c} = \\arg\\max_c P(c)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f 0.16666666666666666\n"
     ]
    }
   ],
   "source": [
    "def P(c):\n",
    "    return prob[c]\n",
    "# the character with the highest probability is given by argmax_c P(c)\n",
    "argmax_char = max(list(n.keys()), key=P)\n",
    "print(argmax_char, P(argmax_char))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Sample size and probability estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that larger samples result in a more accurate measurement of the probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def sample_dist(fdist):\n",
    "    return([ (sample, fdist[sample]) for sample in fdist ])\n",
    "\n",
    "def vertical_bars(sample_dist):\n",
    "    samples = list(map(itemgetter(0), sample_dist))\n",
    "    freqs = list(map(itemgetter(1), sample_dist))\n",
    "    # samples = fdist.samples()\n",
    "    # freqs = [ fdist[sample] for sample in samples ]\n",
    "    labels = [str(s) for s in samples]\n",
    "    fig, ax1 = plt.subplots(figsize=(15, 10))\n",
    "    pos = numpy.arange(len(labels))\n",
    "    ax1.bar(list(pos), list(freqs), facecolor='#9999ff', edgecolor='white')\n",
    "    font = matplotlib.font_manager.FontProperties()\n",
    "    font.set_size('x-large')\n",
    "    for x,y in zip(pos,freqs):\n",
    "        ax1.text(x+0.4, y+0.05, '%s' % labels[x], fontproperties=font, ha='center', va= 'bottom')\n",
    "    plt.tick_params(\\\n",
    "        axis='x',          # changes apply to the x-axis\n",
    "        which='both',      # both major and minor ticks are affected\n",
    "        bottom=False,      # ticks along the bottom edge are off\n",
    "        top=False,         # ticks along the top edge are off\n",
    "        labelbottom=False) # labels along the bottom edge are off\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let us plot the probability distribution over letters when the sample size is 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anodb'u,gcoauaioeandehhisee,rltaesetoeridostteatcisohfhtwyfueoewdoottrsldialqwavdwyieenrtowunrodushe\n"
     ]
    }
   ],
   "source": [
    "sample1 = lettersample(100)\n",
    "print(''.join(sample1.sample[:100])) # print the first 100 chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('a', 8), ('n', 4), ('o', 11), ('d', 7), ('b', 1), (\"'\", 1), ('u', 5), (',', 2), ('g', 1), ('c', 2), ('i', 6), ('e', 13), ('h', 5), ('s', 6), ('r', 5), ('l', 3), ('t', 9), ('f', 2), ('w', 5), ('y', 2), ('q', 1), ('v', 1)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fdist1 = nltk.probability.FreqDist(sample1.sample)\n",
    "print(sample_dist(fdist1))\n",
    "s = sorted(sample_dist(fdist1), reverse=True, key=itemgetter(1))\n",
    "vertical_bars(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now let us take a larger sample of 100,000 characters. The plot of the probability distribution now shows a more accurate likelihood of each character in English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nprtia.telgnaolhbtceaernn'dtwotes:lwhasidiethogut'qciuknusdmldhdayksrwalehtterdutie.eageestnaih,amsd\n"
     ]
    }
   ],
   "source": [
    "sample2 = lettersample(100000)\n",
    "print((''.join(sample2.sample[:100]))) # print the first 100 chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fdist2 = nltk.probability.FreqDist(sample2.sample)\n",
    "vertical_bars(sorted(sample_dist(fdist2), reverse=True, key=itemgetter(1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Random Probability Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Now let us compare a character sample taken from a real English document with a totally random assignment of probabilities to English characters. The difference in the distribution is not just in the assignment of probabilities to individual characters, but the shape of the distribution is altogether different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import string\n",
    "import numpy\n",
    "# set up a random probability distribution over lowercase ASCII characters\n",
    "counts = [ 100*numpy.random.random() for c in string.ascii_lowercase ]\n",
    "sample_dist = [ (c, counts[i]) for (i,c) in enumerate(string.ascii_lowercase) ]\n",
    "vertical_bars(sorted(sample_dist, reverse=True, key=itemgetter(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.015017244892331421\n",
      "0.06966336818041449\n"
     ]
    }
   ],
   "source": [
    "total = sum(counts)\n",
    "# the following is a dictionary comprehension\n",
    "prob = { c: (counts[i] / total) for (i,c) in enumerate(string.ascii_lowercase) }\n",
    "print(prob['e'])\n",
    "print(prob['z'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Joint Probability Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# sample letter bigrams from a document with replacement\n",
    "class bigramsample:\n",
    "    \n",
    "    def __init__(self, num):\n",
    "        self.corpus = [c.lower() for sent in nltk.corpus.gutenberg.sents('carroll-alice.txt') for c in ''.join(sent)]\n",
    "        self.bigrams = [ tuple(self.corpus[i:i+2]) for i in range(len(self.corpus)-1) ]\n",
    "        self.sample = [random.choice(self.bigrams) for i in range(num)]\n",
    "\n",
    "    # __str__ creates a printable representation of the object\n",
    "    def __str__(self):\n",
    "        return ''.join(self.sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e,t\n",
      "w,i\n",
      "k,,\n",
      "e,r\n",
      "e,f\n",
      "e,t\n",
      "t,h\n",
      "r,e\n",
      "a,s\n",
      "t,h\n"
     ]
    }
   ],
   "source": [
    "b = bigramsample(100)\n",
    "print('\\n'.join([\"%c,%c\" % (x,y) for (x,y) in b.sample[:10] ])) # print the first 10 bigrams sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a t: 1\n",
      "n v: 1\n",
      "e n: 2\n",
      "' t: 1\n",
      "u l: 1\n",
      ". ': 1\n",
      "w s: 1\n",
      "i l: 2\n",
      "k :: 1\n",
      "h i: 1\n",
      "sample size: 100\n"
     ]
    }
   ],
   "source": [
    "s = bigramsample(100)\n",
    "n = defaultdict(int)\n",
    "for (x,y) in s.sample:\n",
    "    n[x,y] += 1\n",
    "for (x,y) in list(n.keys())[:10]: # print 10 items from the sample\n",
    "    print(\"%c %c: %d\" % (x, y, n[x,y]))\n",
    "print(\"sample size:\", sum(n.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Sample space $S = \\{ a, b, c, \\ldots, z \\}^2$\n",
    "\n",
    "Random variable $X(x,y) = x$ and $Y(x,y) = y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a t: 0.010000\n",
      "n v: 0.010000\n",
      "e n: 0.020000\n",
      "' t: 0.010000\n",
      "u l: 0.010000\n",
      ". ': 0.010000\n",
      "w s: 0.010000\n",
      "i l: 0.020000\n",
      "k :: 0.010000\n",
      "h i: 0.010000\n"
     ]
    }
   ],
   "source": [
    "total = sum(n.values())\n",
    "prob = { (x,y): (n[x,y] / total) for (x,y) in list(n.keys()) }\n",
    "for (x,y) in list(prob.keys())[:10]: # print 10 probabilities\n",
    "    print(\"%c %c: %f\" % (x, y, prob[x,y]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Finding the argmax of a joint probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The argmax of a joint probability distribution is the values for the joint random variables that returns the highest _joint_ probability. \n",
    "$$\\hat{x},\\hat{y} = \\arg\\max_{x,y} P(X=x,Y=y)$$\n",
    "Which can be written as:\n",
    "$$\\hat{x},\\hat{y} = \\arg\\max_{x,y} P(x,y)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h e: 0.060000\n"
     ]
    }
   ],
   "source": [
    "def P(key):\n",
    "    (x,y) = key\n",
    "    return prob[x,y]\n",
    "# the character with the highest probability is given by argmax_{x,y} P(x,y)\n",
    "(argmax_x, argmax_y) = max(list(n.keys()), key=P)\n",
    "print(\"%c %c: %f\" % (argmax_x, argmax_y, P((argmax_x,argmax_y))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Marginal Probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "A probability distribution over a subset of variables is a _marginal probability_. We can find the probability value of a particular second character by summing over or _marginalizing out_ the first character probabilities.\n",
    "$$ P(Y=d) = \\sum_{x \\in X} P(X=x, Y=d) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('c', 'e'): 0.01, ('h', 'e'): 0.06, ('r', 'e'): 0.01}\n",
      "P(Y=e)=0.080000\n"
     ]
    }
   ],
   "source": [
    "marginal = { (x,y) : prob[x,y] for (x,y) in list(prob.keys()) if y == argmax_y }\n",
    "print(marginal)\n",
    "print(\"P(Y=%c)=%f\" % (argmax_y, sum(marginal.values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Expectation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The expectation with respect to a probability $P$ is a weighted average of the values taken by the random variable (taken from the event space ${\\cal E}$) where the weights are given by the probability $P$.\n",
    "\n",
    "$$ E_P[x] = \\sum_{x \\in {\\cal E}} x \\cdot P(x) $$\n",
    "\n",
    "So if ${\\cal E} = \\{ x_1, x_2, x_3, x_4 \\}$ then:\n",
    "\n",
    "$$ E_P[x] = \\frac{x_1 \\cdot p(x_1) + x_2 \\cdot p(x_2) + x_3 \\cdot p(x_3) + x_4 \\cdot p(x_4)}{p(x_1) + p(x_2) + p(x_3) + p(x_4)} $$\n",
    "\n",
    "which is the same as:\n",
    "\n",
    "$$ E_P[x] = x_1 \\cdot p(x_1) + x_2 \\cdot p(x_2) + x_3 \\cdot p(x_3) + x_4 \\cdot p(x_4) $$\n",
    "\n",
    "For instance if we collect the word lengths from a natural language corpus and collect the probability of occurrence of each length, we can computed the expected value of word length over all words in the vocabulary ${\\cal V}$.\n",
    "\n",
    "$$ E_p[\\ell] = \\sum_{\\ell = \\textrm{len(x) for } x \\in {\\cal V}} \\ell \\cdot P(\\ell) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book: austen-emma.txt\n",
      "Expected word length: 3.7552682315891226\n",
      "\n",
      "Book: austen-persuasion.txt\n",
      "Expected word length: 3.871031159914843\n",
      "\n",
      "Book: austen-sense.txt\n",
      "Expected word length: 3.881371136350794\n",
      "\n",
      "Book: bible-kjv.txt\n",
      "Expected word length: 3.4478209159613487\n",
      "\n",
      "Book: blake-poems.txt\n",
      "Expected word length: 3.503471390950443\n",
      "\n",
      "Book: bryant-stories.txt\n",
      "Expected word length: 3.5004949336788864\n",
      "\n",
      "Book: burgess-busterbrown.txt\n",
      "Expected word length: 3.5167431313610713\n",
      "\n",
      "Book: carroll-alice.txt\n",
      "Expected word length: 3.4010260920551154\n",
      "\n",
      "Book: chesterton-ball.txt\n",
      "Expected word length: 3.8245907047713303\n",
      "\n",
      "Book: chesterton-brown.txt\n",
      "Expected word length: 3.790804410722379\n",
      "\n",
      "Book: chesterton-thursday.txt\n",
      "Expected word length: 3.774276508748356\n",
      "\n",
      "Book: edgeworth-parents.txt\n",
      "Expected word length: 3.50881265338479\n",
      "\n",
      "Book: melville-moby_dick.txt\n",
      "Expected word length: 3.830411128023649\n",
      "\n",
      "Book: milton-paradise.txt\n",
      "Expected word length: 3.887312161115415\n",
      "\n",
      "Book: shakespeare-caesar.txt\n",
      "Expected word length: 3.444121859636899\n",
      "\n",
      "Book: shakespeare-hamlet.txt\n",
      "Expected word length: 3.4637312633832975\n",
      "\n",
      "Book: shakespeare-macbeth.txt\n",
      "Expected word length: 3.4653414001728606\n",
      "\n",
      "Book: whitman-leaves.txt\n",
      "Expected word length: 3.6962481356895207\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def expectation(dist):\n",
    "    sum = 0.0\n",
    "    for len in dist.freqdist():\n",
    "        sum += len * dist.prob(len)\n",
    "        #print len, dist.prob(len)\n",
    "    return sum\n",
    "        \n",
    "for book in nltk.corpus.gutenberg.fileids():\n",
    "    w_len = [len(w) for w in nltk.corpus.gutenberg.words(book)]\n",
    "    len_fd = nltk.FreqDist(w_len)\n",
    "    len_d = nltk.MLEProbDist(len_fd)\n",
    "    print(\"Book:\", book)\n",
    "    print(\"Expected word length:\", expectation(len_d))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entropy is the expected number of bits needed to represent a probability distribution:\n",
    "\n",
    "$$ H(p) = - E_p[ log_2(p(x)) ] $$\n",
    "\n",
    "Or expanding the definition of expectation:\n",
    "\n",
    "$$ H(p) = - \\sum_{x \\in {\\cal E}} p(x) \\cdot log_2(p(x)) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book: austen-emma.txt\n",
      "Entropy: 8.873152285226238\n",
      "\n",
      "Book: austen-persuasion.txt\n",
      "Entropy: 8.859615924145508\n",
      "\n",
      "Book: austen-sense.txt\n",
      "Entropy: 8.89502303490741\n",
      "\n",
      "Book: bible-kjv.txt\n",
      "Entropy: 8.533251092134407\n",
      "\n",
      "Book: blake-poems.txt\n",
      "Entropy: 8.771766636117121\n",
      "\n",
      "Book: bryant-stories.txt\n",
      "Entropy: 8.762926926466157\n",
      "\n",
      "Book: burgess-busterbrown.txt\n",
      "Entropy: 8.326262138210373\n",
      "\n",
      "Book: carroll-alice.txt\n",
      "Entropy: 8.4860818642139\n",
      "\n",
      "Book: chesterton-ball.txt\n",
      "Entropy: 9.293358723948293\n",
      "\n",
      "Book: chesterton-brown.txt\n",
      "Entropy: 9.275800529530137\n",
      "\n",
      "Book: chesterton-thursday.txt\n",
      "Entropy: 9.119791242411557\n",
      "\n",
      "Book: edgeworth-parents.txt\n",
      "Entropy: 8.982968867778386\n",
      "\n",
      "Book: melville-moby_dick.txt\n",
      "Entropy: 9.647923151844278\n",
      "\n",
      "Book: milton-paradise.txt\n",
      "Entropy: 9.674613746909916\n",
      "\n",
      "Book: shakespeare-caesar.txt\n",
      "Entropy: 8.785886795219731\n",
      "\n",
      "Book: shakespeare-hamlet.txt\n",
      "Entropy: 9.045087184622895\n",
      "\n",
      "Book: shakespeare-macbeth.txt\n",
      "Entropy: 9.00374321714706\n",
      "\n",
      "Book: whitman-leaves.txt\n",
      "Entropy: 9.390609764209854\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "def entropy(dist):\n",
    "    score = 0\n",
    "    for k in dist.freqdist():\n",
    "        score += dist.prob(k) * math.log(dist.prob(k),2)\n",
    "    return -1*score\n",
    "    \n",
    "for book in nltk.corpus.gutenberg.fileids():\n",
    "    words = [w for w in nltk.corpus.gutenberg.words(book)]\n",
    "    words_fd = nltk.FreqDist(words)\n",
    "    wprob = nltk.MLEProbDist(words_fd)\n",
    "    print(\"Book:\", book)\n",
    "    print(\"Entropy:\", entropy(wprob))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Entropy\n",
    "\n",
    "Cross Entropy or the Kullback-Liebler divergence from a probability distribution $q$ to another probability distribution $p$ over the same event space is defined as the expected difference between using probability distribution $q$ to encode the samples produced from probability distribution $p$:\n",
    "\n",
    "$$  D(p \\| q) = - E_{ p(x) } \\left[ \\log_2 \\frac{q(x)}{p(x)} \\right] $$\n",
    "\n",
    "Writing out the expectation we get:\n",
    "\n",
    "$$ D(p \\| q) = - \\sum_{x \\in {\\cal E}} p(x) \\log_2 \\frac{q(x)}{p(x)} $$\n",
    "\n",
    "Define:\n",
    "$$H(p) = - \\sum_{x} p(x) \\log_2 p(x)$$\n",
    "$$H(p,q) = - \\sum_{x} p(x) \\log_2 q(x)$$\n",
    "\n",
    "Notice that $H(p)$ is just entropy of probability distribution $p$. Then we can write:\n",
    "\n",
    "$$ D(p \\| q) = H(p,q) - H(p) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book1: austen-emma.txt, Book2: austen-persuasion.txt\n",
      "Cross Entropy: -18.62614399925599\n",
      "\n",
      "Book1: austen-emma.txt, Book2: austen-sense.txt\n",
      "Cross Entropy: -18.62194802829501\n",
      "\n",
      "Book1: austen-emma.txt, Book2: bible-kjv.txt\n",
      "Cross Entropy: -20.585372671682723\n",
      "\n",
      "Book1: austen-emma.txt, Book2: blake-poems.txt\n",
      "Cross Entropy: -18.971264688756463\n",
      "\n",
      "Book1: austen-emma.txt, Book2: bryant-stories.txt\n",
      "Cross Entropy: -19.00771105829231\n",
      "\n",
      "Book1: austen-emma.txt, Book2: burgess-busterbrown.txt\n",
      "Cross Entropy: -18.925326988469592\n",
      "\n",
      "Book1: austen-emma.txt, Book2: carroll-alice.txt\n",
      "Cross Entropy: -18.942102954717413\n",
      "\n",
      "Book1: austen-emma.txt, Book2: chesterton-ball.txt\n",
      "Cross Entropy: -19.120557487378825\n",
      "\n",
      "Book1: austen-emma.txt, Book2: chesterton-brown.txt\n",
      "Cross Entropy: -19.052705303228986\n",
      "\n",
      "Book1: austen-emma.txt, Book2: chesterton-thursday.txt\n",
      "Cross Entropy: -19.136972434602107\n",
      "\n",
      "Book1: austen-emma.txt, Book2: edgeworth-parents.txt\n",
      "Cross Entropy: -18.89448005467921\n",
      "\n",
      "Book1: austen-emma.txt, Book2: melville-moby_dick.txt\n",
      "Cross Entropy: -19.360917770330566\n",
      "\n",
      "Book1: austen-emma.txt, Book2: milton-paradise.txt\n",
      "Cross Entropy: -19.805420418016034\n",
      "\n",
      "Book1: austen-emma.txt, Book2: shakespeare-caesar.txt\n",
      "Cross Entropy: -19.576494041311534\n",
      "\n",
      "Book1: austen-emma.txt, Book2: shakespeare-hamlet.txt\n",
      "Cross Entropy: -19.6627159491278\n",
      "\n",
      "Book1: austen-emma.txt, Book2: shakespeare-macbeth.txt\n",
      "Cross Entropy: -19.577524342568992\n",
      "\n",
      "Book1: austen-emma.txt, Book2: whitman-leaves.txt\n",
      "Cross Entropy: -19.8194579182176\n",
      "\n",
      "Book1: austen-persuasion.txt, Book2: austen-emma.txt\n",
      "Cross Entropy: -18.887523898100994\n",
      "\n",
      "Book1: austen-persuasion.txt, Book2: austen-sense.txt\n",
      "Cross Entropy: -18.840304387587672\n",
      "\n",
      "Book1: austen-persuasion.txt, Book2: bible-kjv.txt\n",
      "Cross Entropy: -20.575263986749697\n",
      "\n",
      "Book1: austen-persuasion.txt, Book2: blake-poems.txt\n",
      "Cross Entropy: -19.06548067469837\n",
      "\n",
      "Book1: austen-persuasion.txt, Book2: bryant-stories.txt\n",
      "Cross Entropy: -19.158537171245783\n",
      "\n",
      "Book1: austen-persuasion.txt, Book2: burgess-busterbrown.txt\n",
      "Cross Entropy: -19.05772436005519\n",
      "\n",
      "Book1: austen-persuasion.txt, Book2: carroll-alice.txt\n",
      "Cross Entropy: -19.09770717145767\n",
      "\n",
      "Book1: austen-persuasion.txt, Book2: chesterton-ball.txt\n",
      "Cross Entropy: -19.270528194941917\n",
      "\n",
      "Book1: austen-persuasion.txt, Book2: chesterton-brown.txt\n",
      "Cross Entropy: -19.205045271088714\n",
      "\n",
      "Book1: austen-persuasion.txt, Book2: chesterton-thursday.txt\n",
      "Cross Entropy: -19.29393445925216\n",
      "\n",
      "Book1: austen-persuasion.txt, Book2: edgeworth-parents.txt\n",
      "Cross Entropy: -19.083313684886143\n",
      "\n",
      "Book1: austen-persuasion.txt, Book2: melville-moby_dick.txt\n",
      "Cross Entropy: -19.496952501591206\n",
      "\n",
      "Book1: austen-persuasion.txt, Book2: milton-paradise.txt\n",
      "Cross Entropy: -19.855631262541507\n",
      "\n",
      "Book1: austen-persuasion.txt, Book2: shakespeare-caesar.txt\n",
      "Cross Entropy: -19.679618619071277\n",
      "\n",
      "Book1: austen-persuasion.txt, Book2: shakespeare-hamlet.txt\n",
      "Cross Entropy: -19.763505114323443\n",
      "\n",
      "Book1: austen-persuasion.txt, Book2: shakespeare-macbeth.txt\n",
      "Cross Entropy: -19.653885838877244\n",
      "\n",
      "Book1: austen-persuasion.txt, Book2: whitman-leaves.txt\n",
      "Cross Entropy: -19.935360839410592\n",
      "\n",
      "Book1: austen-sense.txt, Book2: austen-emma.txt\n",
      "Cross Entropy: -18.76991624898378\n",
      "\n",
      "Book1: austen-sense.txt, Book2: austen-persuasion.txt\n",
      "Cross Entropy: -18.717432963703104\n",
      "\n",
      "Book1: austen-sense.txt, Book2: bible-kjv.txt\n",
      "Cross Entropy: -20.535766170541173\n",
      "\n",
      "Book1: austen-sense.txt, Book2: blake-poems.txt\n",
      "Cross Entropy: -19.002670244583115\n",
      "\n",
      "Book1: austen-sense.txt, Book2: bryant-stories.txt\n",
      "Cross Entropy: -19.09797885438281\n",
      "\n",
      "Book1: austen-sense.txt, Book2: burgess-busterbrown.txt\n",
      "Cross Entropy: -19.051917825454446\n",
      "\n",
      "Book1: austen-sense.txt, Book2: carroll-alice.txt\n",
      "Cross Entropy: -19.042281957448807\n",
      "\n",
      "Book1: austen-sense.txt, Book2: chesterton-ball.txt\n",
      "Cross Entropy: -19.237269544955485\n",
      "\n",
      "Book1: austen-sense.txt, Book2: chesterton-brown.txt\n",
      "Cross Entropy: -19.174351339814013\n",
      "\n",
      "Book1: austen-sense.txt, Book2: chesterton-thursday.txt\n",
      "Cross Entropy: -19.25753940037354\n",
      "\n",
      "Book1: austen-sense.txt, Book2: edgeworth-parents.txt\n",
      "Cross Entropy: -18.973783748414938\n",
      "\n",
      "Book1: austen-sense.txt, Book2: melville-moby_dick.txt\n",
      "Cross Entropy: -19.45013202678596\n",
      "\n",
      "Book1: austen-sense.txt, Book2: milton-paradise.txt\n",
      "Cross Entropy: -19.787625784001918\n",
      "\n",
      "Book1: austen-sense.txt, Book2: shakespeare-caesar.txt\n",
      "Cross Entropy: -19.6434549566207\n",
      "\n",
      "Book1: austen-sense.txt, Book2: shakespeare-hamlet.txt\n",
      "Cross Entropy: -19.71876507355766\n",
      "\n",
      "Book1: austen-sense.txt, Book2: shakespeare-macbeth.txt\n",
      "Cross Entropy: -19.620469987798234\n",
      "\n",
      "Book1: austen-sense.txt, Book2: whitman-leaves.txt\n",
      "Cross Entropy: -19.871086715279798\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def cross_entropy(p,q):\n",
    "    H_p_q = 0\n",
    "    for k in p.freqdist():\n",
    "        H_p_q += p.prob(k) * math.log(q.prob(k),2)\n",
    "    return(H_p_q - entropy(p))\n",
    "\n",
    "wprob = {}\n",
    "for book in nltk.corpus.gutenberg.fileids():\n",
    "    words = [w for w in nltk.corpus.gutenberg.words(book)]\n",
    "    words_fd = nltk.FreqDist(words)\n",
    "    # Instead of the maximum likelihood (MLE) we use a Laplace\n",
    "    # distribution to handle words that are used in one book\n",
    "    # but not the other\n",
    "    wprob[book] = nltk.LaplaceProbDist(words_fd)\n",
    "\n",
    "for book1 in nltk.corpus.gutenberg.fileids():\n",
    "    for book2 in nltk.corpus.gutenberg.fileids():\n",
    "        if book1.startswith(\"austen-\") and book1 != book2:\n",
    "            print(\"Book1: {}, Book2: {}\".format(book1, book2))\n",
    "            print(\"Cross Entropy:\", cross_entropy(wprob[book1], wprob[book2]))\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutual Information\n",
    "\n",
    "Mutual information or $I(X;Y)$ computes the similarity between two random variables $X$ and $Y$ by computing the cross entropy between assuming independence between $X$ and $Y$, which is $p(X)p(Y)$ and not assuming independence $p(X,Y)$ which is the joint probability. \n",
    "\n",
    "$$ I(X;Y) = D(p(x,y) \\| p(x)p(y)) = \\sum_x \\sum_y p(x,y) \\log_2 \\frac{p(x,y)}{p(x)p(y)} $$\n",
    "\n",
    "The reasoning is: if the distribution $P(X,Y)$ is close to $P(X)P(Y)$ then the variables $X$ and $Y$ are independently distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Book: austen-emma.txt\n",
      "Total MI Score: 3.8394953949098727\n",
      "mrs weston\n",
      "had been\n",
      "frank churchill\n",
      "have been\n",
      "could not\n",
      "miss woodhouse\n",
      "she had\n",
      "any thing\n",
      "she was\n",
      "mrs elton\n",
      "did not\n",
      "miss fairfax\n",
      "jane fairfax\n",
      "miss bates\n",
      "every thing \n",
      "\n",
      "\n",
      "Book: austen-persuasion.txt\n",
      "Total MI Score: 4.323107083650349\n",
      "captain wentworth\n",
      "had been\n",
      "lady russell\n",
      "sir walter\n",
      "she had\n",
      "could not\n",
      "they were\n",
      "have been\n",
      "did not\n",
      "mrs clay\n",
      "mrs smith\n",
      "she was\n",
      "mrs musgrove\n",
      "she could\n",
      "captain benwick \n",
      "\n",
      "\n",
      "Book: austen-sense.txt\n",
      "Total MI Score: 4.070847559161385\n",
      "mrs jennings\n",
      "colonel brandon\n",
      "sir john\n",
      "lady middleton\n",
      "have been\n",
      "mrs dashwood\n",
      "could not\n",
      "did not\n",
      "had been\n",
      "she had\n",
      "her sister\n",
      "they were\n",
      "she was\n",
      "every thing\n",
      "her own \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import math\n",
    "from operator import itemgetter\n",
    "\n",
    "verbose = False\n",
    "reverse_flag = True\n",
    "\n",
    "def collocations(words):\n",
    "    # Count the words and bigrams\n",
    "    wfd = nltk.FreqDist(words)\n",
    "    pfd = nltk.FreqDist(tuple(words[i:i+2]) for i in range(len(words)-1))\n",
    "\n",
    "    scored = [((w1,w2), mi_score(w1, w2, wfd, pfd)) for w1, w2 in pfd]\n",
    "    total_mi_score = 0.0\n",
    "    for ((w1, w2), score) in scored:\n",
    "        total_mi_score += score\n",
    "    print(\"Total MI Score:\", total_mi_score)\n",
    "    scored.sort(key=itemgetter(1), reverse=reverse_flag)\n",
    "    return list(map(itemgetter(0), scored))\n",
    "\n",
    "def mi_score(word1, word2, wfd, pfd):\n",
    "    wpd = nltk.MLEProbDist(wfd)\n",
    "    ppd = nltk.MLEProbDist(pfd)\n",
    "    px = wpd.prob(word1)\n",
    "    py = wpd.prob(word2)\n",
    "    pxy = ppd.prob( (word1, word2) )\n",
    "    mutual_information_score = pxy * math.log((pxy / (px * py)), 2)\n",
    "    if verbose:\n",
    "        print('mi_score: %s, %s: px=%lf py=%lf pxy=%lf mi_score:%lf' % (word1, word2, px, py, pxy, mutual_information_score))\n",
    "    return mutual_information_score\n",
    "\n",
    "def score(word1, word2, wfd, pfd, power=3):\n",
    "    freq1 = wfd[word1]\n",
    "    freq2 = wfd[word2]\n",
    "    freq12 = pfd[(word1, word2)]\n",
    "    return freq12 ** power / float(freq1 * freq2)\n",
    "\n",
    "austenbooks = ['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt']\n",
    "#austenbooks = ['austen-emma.txt']\n",
    "for book in austenbooks:\n",
    "    words = [ word.lower() for word in nltk.corpus.gutenberg.words(book) if len(word) > 2]\n",
    "    print(\"Book:\", book)\n",
    "    print(\"\\n\".join([w1+' '+w2 for w1, w2 in collocations(words)[:15]]), \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "#from IPython.core.display import HTML\n",
    "\n",
    "#def css_styling():\n",
    "#    styles = open(\"../css/notebook.css\", \"r\").read()\n",
    "#    return HTML(styles)\n",
    "#css_styling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def horizontal_bars(fdist):\n",
    "    samples = fdist.samples()\n",
    "    freqs = [ fdist[sample] for sample in samples ]\n",
    "    labels = [\"'\" + str(s) + \"'\" for s in samples]\n",
    "    fig, ax1 = plt.subplots(figsize=(15, 10))\n",
    "    plt.subplots_adjust(left=0.115, right=0.88)\n",
    "    pos = numpy.arange(len(labels))+0.5    # Center bars on the Y-axis ticks\n",
    "    rects = ax1.barh(pos, freqs, align='center', height=0.5, color='m')\n",
    "    ax1.axis([0, fdist[fdist.max()], 0, len(labels)])\n",
    "    pylab.yticks(pos, labels)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
