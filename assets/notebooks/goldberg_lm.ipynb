{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The unreasonable effectiveness of Character-level Language Models\n",
    "## (and why RNNs are still cool)\n",
    "\n",
    "### [Yoav Goldberg](http://www.cs.biu.ac.il/~yogo)\n",
    "\n",
    "RNNs, LSTMs and Deep Learning are all the rage, and a recent [blog post](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) by Andrej Karpathy is doing a great job explaining what these models are and how to train them.\n",
    "It also provides some very impressive results of what they are capable of.  This is a great post, and if you are interested in natural language, machine learning or neural networks you should definitely read it. \n",
    "\n",
    "Go read it now, then come back here. \n",
    "\n",
    "You're back? good. Impressive stuff, huh? How could the network learn to immitate the input like that?\n",
    "Indeed. I was quite impressed as well.\n",
    "\n",
    "However, it feels to me that most readers of the post are impressed by the wrong reasons.\n",
    "This is because they are not familiar with **unsmoothed maximum-liklihood character level language models** and their unreasonable effectiveness at generating rather convincing natural language outputs.\n",
    "\n",
    "In what follows I will briefly describe these character-level maximum-likelihood langauge models, which are much less magical than RNNs and LSTMs, and show that they too can produce a rather convincing Shakespearean prose. I will also show about 30 lines of python code that take care of both training the model and generating the output. Compared to this baseline, the RNNs may seem somehwat less impressive. So why was I impressed? I will explain this too, below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsmoothed Maximum Likelihood Character Level Language Model \n",
    "\n",
    "The name is quite long, but the idea is very simple.  We want a model whose job is to guess the next character based on the previous $n$ letters. For example, having seen `ello`, the next characer is likely to be either a commma or space (if we assume is is the end of the word \"hello\"), or the letter `w` if we believe we are in the middle of the word \"mellow\". Humans are quite good at this, but of course seeing a larger history makes things easier (if we were to see 5 letters instead of 4, the choice between space and `w` would have been much easier).\n",
    "\n",
    "We will call $n$, the number of letters we need to guess based on, the _order_ of the language model.\n",
    "\n",
    "RNNs and LSTMs can potentially learn infinite-order language model (they guess the next character based on a \"state\" which supposedly encode all the previous history). We here will restrict ourselves to a fixed-order language model.\n",
    "\n",
    "So, we are seeing $n$ letters, and need to guess the $n+1$th one. We are also given a large-ish amount of text (say, all of Shakespear works) that we can use. How would we go about solving this task?\n",
    "\n",
    "Mathematiacally, we would like to learn a function $P(c | h)$. Here, $c$ is a character, $h$ is a $n$-letters history, and $P(c|h)$ stands for how likely is it to see $c$ after we've seen $h$.\n",
    "\n",
    "Perhaps the simplest approach would be to just count and divide (a.k.a **maximum likelihood estimates**). We will count the number of times each letter $c'$ appeared after $h$, and divide by the total numbers of letters appearing after $h$. The **unsmoothed** part means that if we did not see a given letter following $h$, we will just give it a probability of zero.\n",
    "\n",
    "And that's all there is to it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Code\n",
    "Here is the code for training the model. `fname` is a file to read the characters from. `order` is the history size to consult. Note that we pad the data with leading `~` so that we also learn how to start.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import *\n",
    "\n",
    "def train_char_lm(fname, order=4):\n",
    "    data = open(fname).read()\n",
    "    lm = defaultdict(Counter)\n",
    "    pad = \"~\" * order\n",
    "    data = pad + data\n",
    "    for i in range(len(data)-order):\n",
    "        history, char = data[i:i+order], data[i+order]\n",
    "        lm[history][char]+=1\n",
    "    def normalize(counter):\n",
    "        s = float(sum(counter.values()))\n",
    "        return [(c,cnt/s) for c,cnt in counter.items()]\n",
    "    outlm = {hist:normalize(chars) for hist, chars in lm.items()}\n",
    "    return outlm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train it on Andrej's Shakespears's text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL transformed to HTTPS due to an HSTS policy\n",
      "--2018-09-20 14:45:22--  https://cs.stanford.edu/people/karpathy/char-rnn/shakespeare_input.txt\n",
      "Resolving cs.stanford.edu (cs.stanford.edu)... 171.64.64.64\n",
      "Connecting to cs.stanford.edu (cs.stanford.edu)|171.64.64.64|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4573338 (4.4M) [text/plain]\n",
      "Saving to: ‘shakespeare_input.txt.3’\n",
      "\n",
      "shakespeare_input.t 100%[===================>]   4.36M  9.16MB/s    in 0.5s    \n",
      "\n",
      "2018-09-20 14:45:22 (9.16 MB/s) - ‘shakespeare_input.txt.3’ saved [4573338/4573338]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://cs.stanford.edu/people/karpathy/char-rnn/shakespeare_input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = train_char_lm(\"shakespeare_input.txt\", order=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok. Now let's do some queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('r', 0.059625212947189095),\n",
       " ('w', 0.817717206132879),\n",
       " ('u', 0.03747870528109029),\n",
       " (',', 0.027257240204429302),\n",
       " (' ', 0.013628620102214651),\n",
       " ('.', 0.0068143100511073255),\n",
       " ('?', 0.0068143100511073255),\n",
       " (':', 0.005110732538330494),\n",
       " ('n', 0.0017035775127768314),\n",
       " (\"'\", 0.017035775127768313),\n",
       " ('!', 0.0068143100511073255)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm['ello']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('t', 1.0)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm['Firs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('C', 0.09550561797752809),\n",
       " ('f', 0.011235955056179775),\n",
       " ('i', 0.016853932584269662),\n",
       " ('t', 0.05377207062600321),\n",
       " ('u', 0.0016051364365971107),\n",
       " ('S', 0.16292134831460675),\n",
       " ('h', 0.019261637239165328),\n",
       " ('s', 0.03290529695024077),\n",
       " ('R', 0.0008025682182985554),\n",
       " ('b', 0.024879614767255216),\n",
       " ('c', 0.012841091492776886),\n",
       " ('O', 0.018459069020866775),\n",
       " ('w', 0.024077046548956663),\n",
       " ('a', 0.02247191011235955),\n",
       " ('m', 0.02247191011235955),\n",
       " ('n', 0.020064205457463884),\n",
       " ('I', 0.009630818619582664),\n",
       " ('L', 0.10674157303370786),\n",
       " ('M', 0.0593900481540931),\n",
       " ('l', 0.01043338683788122),\n",
       " ('o', 0.030497592295345103),\n",
       " ('H', 0.0040128410914927765),\n",
       " ('d', 0.015248796147672551),\n",
       " ('W', 0.033707865168539325),\n",
       " ('K', 0.008025682182985553),\n",
       " ('q', 0.0016051364365971107),\n",
       " ('G', 0.0898876404494382),\n",
       " ('g', 0.011235955056179775),\n",
       " ('k', 0.0040128410914927765),\n",
       " ('e', 0.0032102728731942215),\n",
       " ('y', 0.002407704654895666),\n",
       " ('r', 0.0072231139646869984),\n",
       " ('p', 0.00882825040128411),\n",
       " ('A', 0.0056179775280898875),\n",
       " ('P', 0.014446227929373997),\n",
       " ('F', 0.012038523274478331),\n",
       " ('v', 0.002407704654895666),\n",
       " ('T', 0.0032102728731942215),\n",
       " ('D', 0.0032102728731942215),\n",
       " ('B', 0.009630818619582664),\n",
       " ('N', 0.0008025682182985554),\n",
       " (\"'\", 0.0008025682182985554),\n",
       " ('E', 0.0016051364365971107)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm['rst ']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So `ello` is followed by either space, punctuation or `w` (or `r`, `u`, `n`), `Firs` is pretty much deterministic, and the word following `ist ` can start with pretty much every letter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating from the model\n",
    "Generating is also very simple. To generate a letter, we will take the history, look at the last $order$ characteters, and then sample a random letter based on the corresponding distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random\n",
    "\n",
    "def generate_letter(lm, history, order):\n",
    "        history = history[-order:]\n",
    "        dist = lm[history]\n",
    "        x = random()\n",
    "        for c,v in dist:\n",
    "            x = x - v\n",
    "            if x <= 0: return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate a passage of $k$ characters, we just seed it with the initial history and run letter generation in a loop, updating the history at each turn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(lm, order, nletters=1000):\n",
    "    history = \"~\" * order\n",
    "    out = []\n",
    "    for i in range(nletters):\n",
    "        c = generate_letter(lm, history, order)\n",
    "        history = history[-order:] + c\n",
    "        out.append(c)\n",
    "    return \"\".join(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generated Shakespeare from different order models\n",
    "\n",
    "Let's try to generate text based on different language-model orders. Let's start with something silly:\n",
    "\n",
    "### order 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fir, lay, wit I'll.\n",
      "\n",
      "Everis perve mads, hold For day 'come thou losess joinglaut love;\n",
      "Andere say youl'd ged-wor:\n",
      "If of an der they, aw he youlive; I, yourstrood win useld fle in thou\n",
      "Thowand upost, be\n",
      "FEENRY Brid with,\n",
      "It fripinsighte prow: he thided\n",
      "MADY VINDA:\n",
      "Prinjoy prot ithathy is the to stall welfsay hathe coun I man his calls con:'\n",
      "'You, God noth, the go,\n",
      "Whatumne fath hen theas, van.\n",
      "The beeper handeciortill will the way VING CASTAVISTAFF:\n",
      "\n",
      "Be to min spen thou, st of te giderew amen, I arthe yourbuty; I cou to prent?\n",
      "\n",
      "Com o'er mad.\n",
      "As my thus, ink a was got brich th hionst heake in hone'ere, be,\n",
      "Leoull to my low plabide fat, andell go for fring and bitherwity a for'strood,\n",
      "As dour therwit wing-joyse your pellost uppriflume? I come.\n",
      "\n",
      "POLK:\n",
      "Nay fuld mippy; feres; the nits foliemenfor sub, wearran a gail?\n",
      "\n",
      "QUICUS Paw, no hishic whould\n",
      "scrow ye, an:\n",
      "Com or lover. I wor dold my comfortand\n",
      "HESS PAGO:\n",
      "Whe falf; withy, aturld hou se re\n",
      "The he this in foollove, a goo.\n",
      "\n",
      "Fireglive to ote\n"
     ]
    }
   ],
   "source": [
    "lm = train_char_lm(\"shakespeare_input.txt\", order=2)\n",
    "print(generate_text(lm, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not so great.. but what if we increase the order to 4?\n",
    "\n",
    "### order 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Helent citizen:\n",
      "My fairs.\n",
      "\n",
      "POSTHUMUS LEONATO:\n",
      "In shake\n",
      "my safests at is too rot? What, indirection:\n",
      "Then humilia,\n",
      "To give mistance, he world be body, heavy dear.\n",
      "\n",
      "TALBOT:\n",
      "Arise; who day in a bristiano dare let the must is again the not fire.\n",
      "\n",
      "MONTANO:\n",
      "Lady:\n",
      "Welcomes of a most be, if noble Barbaron we victor, I cares.\n",
      "\n",
      "Frence no leave a noble Antony.\n",
      "\n",
      "BERT:\n",
      "Indeed.\n",
      "Kind my child our bound, I head, be habit in him for powers\n",
      "Detest, cher, let it.\n",
      "\n",
      "Chain'd bonds them with he mortal, sir.\n",
      "\n",
      "ISABELLA:\n",
      "I am so their batten hath me.\n",
      "\n",
      "PRINCESS:\n",
      "God of that I may.\n",
      "\n",
      "BAPTISTA:\n",
      "A year, thou made back pass fill not purch a hey:\n",
      "Think the man between likeness of brother, fee-sick\n",
      "I shows; but is presume of salt be death.\n",
      "Her her any, such take his gold,\n",
      "It mind,\n",
      "To-nightful sleep!\n",
      "Speak in out, beforeigned not your mine other but thou heart.\n",
      "\n",
      "First Clown: happily, for my bonesty, this\n",
      "Make thy for the time to all use me and a heart the devised.\n",
      "I wonder'd in the got?\n",
      "\n",
      "CASSANIO:\n",
      "Writely educats.\n"
     ]
    }
   ],
   "source": [
    "lm = train_char_lm(\"shakespeare_input.txt\", order=4)\n",
    "print(generate_text(lm, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Lawren me,\n",
      "Than to does herefore,\n",
      "Acquail from our many a tallow.\n",
      "\n",
      "HELENA:\n",
      "Canst husband to me founds, unto?\n",
      "\n",
      "Protectors too.\n",
      "\n",
      "MARK ANTONIO:\n",
      "Lay him or where no cool and damned love enemy's derive thus who, says but them. Peace,\n",
      "Who, I wilt the hungry patient all be not the vapoured be yet his tents of other reason\n",
      "Unto them\n",
      "Is not so young me mouth: Troilus!\n",
      "Here is\n",
      "But ye! There's at service ingration\n",
      "In signity are no make it once to theres are her your courteer thy to Caesar, assure, bond brother'd hold serve you tell-eyed deeds come lies appeals are wink'd on he power'd in returns.\n",
      "\n",
      "TRANIO:\n",
      "Be you go with nod; O wick\n",
      "That searches\n",
      "To plague\n",
      "Of his\n",
      "unbolts that me\n",
      "Holdier all,\n",
      "Ere I see,\n",
      "And, for this in pains wife's sort\n",
      "To conquet our lease\n",
      "your him and senterbury! Flavish for sake merce he is vantague sension my fathere, if mine would be perce and which lightning,\n",
      "I wench gives Aufidius sometime; but he reeky past.\n",
      "\n",
      "DUKE OF GAUNT:\n",
      "Wait up,\n",
      "Where pathink\n",
      "Might\n",
      "They dost gra\n"
     ]
    }
   ],
   "source": [
    "lm = train_char_lm(\"shakespeare_input.txt\", order=4)\n",
    "print(generate_text(lm, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is already quite reasonable, and reads like English. Just 4 letters history! What if we increase it to 7?\n",
    "\n",
    "### order 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "This wealth,\n",
      "Methinks in passage to glad your indiscreetly as a call\n",
      "To every\n",
      "thing than a pound of Hotspur's name then; 'neighbour, he shall we at thy husband for me:\n",
      "When he was cast: and your blessed Milford go,\n",
      "And leave here from honour sets him too.\n",
      "\n",
      "YORK:\n",
      "I will hold therefore, hence, awake him a desire it: speak more in my passionate my grief lodged to our flighty protest the flight, awhile; but I love these yellow stockings for the ripe wants their wills; so that watch,\n",
      "That have been the snake,\n",
      "For Doll is in the gibbets and these\n",
      "Which time\n",
      "Be somewhat suit might be fortunes for twenty valiant I am\n",
      "Last night at Herne their villanous shamed me, Master Brook, whereon he should humours; throw thine eyes, earls, down into desperately; you are both the earth, becomes to make one more.\n",
      "\n",
      "DUKE:\n",
      "But, silence with Mowbray?\n",
      "\n",
      "JOHN TALBOT:\n",
      "The breaking it on.\n",
      "Ay, marry; I'll know that name be Horatio,--or I do fear the sentence of ducats?' Or\n",
      "Shall more continent:\n",
      "He hath\n"
     ]
    }
   ],
   "source": [
    "lm = train_char_lm(\"shakespeare_input.txt\", order=7)\n",
    "print(generate_text(lm, 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How about 10?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Would you with the loss\n",
      "Of what is done cannot reason, beldams as you are all well.\n",
      "Write me a prologue; and let the clothes that shall revive:\n",
      "Upon a wooden one?\n",
      "\n",
      "MARGARET:\n",
      "Let me give light\n",
      "To the understand I think\n",
      "The duke is very willingly.\n",
      "\n",
      "EARL OF WORCESTER:\n",
      "Ay, grief, I fear me, will never tremble: my life\n",
      "for yours.\n",
      "\n",
      "IACHIMO:\n",
      "Should you be.\n",
      "\n",
      "ROSALIND:\n",
      "I have made our porter? My master!\n",
      "\n",
      "GLOUCESTER:\n",
      "But have I none,\n",
      "But what is done, spurn her home but this populous\n",
      "And here she comes towards his design\n",
      "Moves like a god! the beauty thinks it were a baby still. I love you; and with most austere\n",
      "sanctimony be the gods,\n",
      "Let's kill him rather. I'll do something give him a present day he is deliver'd of these days!\n",
      "A giving hand, thou great commander and our son.\n",
      "\n",
      "QUEEN ELIZABETH:\n",
      "Poor heart, advise:\n",
      "An you be mine, my lord?\n",
      "\n",
      "HAMLET:\n",
      "And smelt so? pah!\n",
      "\n",
      "HORATIO:\n",
      "As thou lovest me not; for he that buildeth on the whole weapons. Keep them all;\n",
      "By God, he be not one aliv\n"
     ]
    }
   ],
   "source": [
    "lm = train_char_lm(\"shakespeare_input.txt\", order=10)\n",
    "print(generate_text(lm, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This works pretty well\n",
    "\n",
    "With an order of 4, we already get quite reasonable results. Increasing the order to 7 (~word and a half of history) or 10 (~two short words of history) already gets us quite passable Shakepearan text. I'd say it is on par with the examples in Andrej's post. And how simple and un-mystical the model is!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So why am I impressed with the RNNs after all?\n",
    "\n",
    "Generating English a character at a time -- not so impressive in my view. The RNN needs to learn the previous $n$ letters, for a rather small $n$, and that's it. \n",
    "\n",
    "However, the code-generation example is very impressive. Why? because of the context awareness. Note that in all of the posted examples, the code is well indented, the braces and brackets are correctly nested, and even the comments start and end correctly. This is not something that can be achieved by simply looking at the previous $n$ letters. \n",
    "\n",
    "If the examples are not cherry-picked, and the output is generally that nice, then the LSTM did learn something not trivial at all.\n",
    "\n",
    "Just for the fun of it, let's see what our simple language model does with the linux-kernel code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL transformed to HTTPS due to an HSTS policy\n",
      "--2018-09-20 14:47:10--  https://cs.stanford.edu/people/karpathy/char-rnn/linux_input.txt\n",
      "Resolving cs.stanford.edu (cs.stanford.edu)... 171.64.64.64\n",
      "Connecting to cs.stanford.edu (cs.stanford.edu)|171.64.64.64|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 6206996 (5.9M) [text/plain]\n",
      "Saving to: ‘linux_input.txt.1’\n",
      "\n",
      "linux_input.txt.1   100%[===================>]   5.92M  9.67MB/s    in 0.6s    \n",
      "\n",
      "2018-09-20 14:47:11 (9.67 MB/s) - ‘linux_input.txt.1’ saved [6206996/6206996]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://cs.stanford.edu/people/karpathy/char-rnn/linux_input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xa9 in position 5809090: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-5895268f4e5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_char_lm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"linux_input.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerate_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-1948431b5e6a>\u001b[0m in \u001b[0;36mtrain_char_lm\u001b[0;34m(fname, order)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_char_lm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mlm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCounter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mpad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"~\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;31m# decode input (taking the buffer into account)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsumed\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m         \u001b[0;31m# keep undecoded input until the next call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconsumed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xa9 in position 5809090: invalid start byte"
     ]
    }
   ],
   "source": [
    "lm = train_char_lm(\"linux_input.txt\", order=10)\n",
    "print(generate_text(lm, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = train_char_lm(\"linux_input.txt\", order=15)\n",
    "print(generate_text(lm, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = train_char_lm(\"linux_input.txt\", order=20)\n",
    "print(generate_text(lm, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(generate_text(lm, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(generate_text(lm, 20, nletters=5000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Order 10 is pretty much junk. In order 15 things sort-of make sense, but we jump abruptly between the \n",
    "and by order 20 we are doing quite nicely -- but are far from keeping good indentation and brackets. \n",
    "\n",
    "How could we? we do not have the memory, and these things are not modeled at all. While we could quite easily enrich our model to support also keeping track of brackets and indentation (by adding information such as \"have I seen ( but not )\" to the conditioning history), this requires extra work, non-trivial human reasoning, and will make the model significantly more complex. \n",
    "\n",
    "The LSTM, on the other hand, seemed to have just learn it on its own. And that's impressive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunss.otf');\n",
       "    }\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        font-weight: bold;\n",
       "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunsx.otf');\n",
       "    }\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        font-style: oblique;\n",
       "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunsi.otf');\n",
       "    }\n",
       "    @font-face {\n",
       "        font-family: \"Computer Modern\";\n",
       "        font-weight: bold;\n",
       "        font-style: oblique;\n",
       "        src: url('http://9dbb143991406a7c655e-aa5fcb0a5a4ec34cff238a2d56ca4144.r56.cf5.rackcdn.com/cmunso.otf');\n",
       "    }\n",
       "    div.cell{\n",
       "        width:800px;\n",
       "        font-size: 110%;\n",
       "        margin-left:5% !important;\n",
       "        margin-right:auto;\n",
       "    }\n",
       "    h1 {\n",
       "        font-family: Helvetica, serif;\n",
       "    }\n",
       "    h4{\n",
       "        margin-top:12px;\n",
       "        margin-bottom: 3px;\n",
       "       }\n",
       "    div.text_cell_render{\n",
       "        font-family: Computer Modern, \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;\n",
       "        line-height: 145%;\n",
       "        font-size: 110%;\n",
       "        width:800px;\n",
       "        margin-left:auto;\n",
       "        margin-right:auto;\n",
       "    }\n",
       "    .CodeMirror{\n",
       "            font-family: \"Source Code Pro\", source-code-pro,Consolas, monospace;\n",
       "            font-size: 110%;\n",
       "    }\n",
       "    .prompt{\n",
       "        display: None;\n",
       "    }\n",
       "    .text_cell_render h5 {\n",
       "        font-weight: 300;\n",
       "        font-size: 22pt;\n",
       "        color: #4057A1;\n",
       "        font-style: italic;\n",
       "        margin-bottom: .5em;\n",
       "        margin-top: 0.5em;\n",
       "        display: block;\n",
       "    }\n",
       "    \n",
       "    .warning{\n",
       "        color: rgb( 240, 20, 20 )\n",
       "        }  \n",
       "\n",
       "</style>\n",
       "<script>\n",
       "    MathJax.Hub.Config({\n",
       "                        TeX: {\n",
       "                           extensions: [\"AMSmath.js\"]\n",
       "                           },\n",
       "                tex2jax: {\n",
       "                    inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\n",
       "                    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ]\n",
       "                },\n",
       "                displayAlign: 'center', // Change this to 'center' to center equations.\n",
       "                \"HTML-CSS\": {\n",
       "                    styles: {'.MathJax_Display': {\"margin\": 4}}\n",
       "                }\n",
       "        });\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "\n",
    "def css_styling():\n",
    "    styles = open(\"../css/notebook.css\", \"r\").read()\n",
    "    return HTML(styles)\n",
    "css_styling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
