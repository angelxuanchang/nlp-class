---
layout: default
img: escherbabel
img_link: http://en.wikipedia.org/wiki/Tower_of_Babel_(M._C._Escher)
caption: "1928 woodcut by M. C. Escher showing the Tower of Babel."
title: "Project"
active_tab: project
---

# Final Project

<span class="text-info">Start by {{ site.hwdates[5].startdate }} or earlier</span> |
<span class="text-warning">Due on {{ site.hwdates[5].deadline }}</span>

The class project is an opportunity for you to apply your newly acquired skills in NLP towards an in-depth application and/or research problem.
Your project should aim to answer a scientific question and provide some kind of scientific knowledge gain similar to typical NLP research papers.

## Project Ideas


You should pick something you are passionate about or something you find interesting.  When selecting a project, you should make sure that you can find an well-defined dataset that you can use for your project.

Possible projects types include:
* Re-implementing / rereproducing a recent paper
* Applying an existing neural model to a new task
* Implementing a complex neural architecture
* Proposing a new neural model or a new variation of an existing model
* Proposing a new training, optimization, or evaluation scheme
* Experimental and/or theoretical analysis of a NLP model

For interesting project ideas, consider reading papers at top publishing venues for
* NLP: ACL, EMNLP, TACL, NAACL, EACL (see [http://www.aclweb.org/anthology/](http://www.aclweb.org/anthology/) for many NLP publications)
* Machine learning: NeurIPS, ICLR, ICML 

You can also checkout the titles of group projects from [past terms](project_titles) or final projects from [Stanford CS224n](https://nlp.stanford.edu/courses/cs224n/) for inspiration.

## Resources

A list of shared task datasets are provided below.
In some cases you can also extend your homework code to produce innovative project ideas for these tasks.

### Shared Task Collections

* [Torchtext](https://torchtext.readthedocs.io/en/latest/)
* [Sebastian Ruder's curated collection](https://nlpprogress.com/)
* [Datasets for Natural Language Processing](https://machinelearningmastery.com/datasets-natural-language-processing/)
* [Kaggle NLP Tasks](https://www.kaggle.com/datasets?sortBy=hottest&group=public&page=1&pageSize=20&size=sizeAll&filetype=fileTypeAll&license=licenseAll&tagids=13204%2C11208%2C2107)

#### CoNLL Shared Tasks

* [CoNLL Shared Tasks](http://www.conll.org/previous-tasks)
* [CoNLL 2003 Named Entity Recognition Task](https://www.clips.uantwerpen.be/conll2003/ner/)
* [CoNLL 2000 Chunking Task](https://www.clips.uantwerpen.be/conll2000/chunking/)
* [CoNLL 2018 Multilingual Parsing](http://universaldependencies.org/conll18/)

#### SemEval Shared Tasks

* [SemEval 2018](http://alt.qcri.org/semeval2018/index.php?id=tasks)
* [SemEval 2017](http://alt.qcri.org/semeval2017/index.php?id=tasks)
* [SemEval 2016](http://alt.qcri.org/semeval2016/index.php?id=tasks)
* [SemEval 2015](http://alt.qcri.org/semeval2015/index.php?id=tasks)
* [SemEval 2014](http://alt.qcri.org/semeval2014/index.php?id=tasks)

### Classification Tasks

* [Toxic Comment Classification](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge)
* [Fake News Challenge](https://github.com/FakeNewsChallenge/fnc-10)
* [Spam / Click-bait detection](https://www.kaggle.com/therohk/examine-the-examiner)

### Information Extraction

* [Drug-Drug Interaction Extraction](http://labda.inf.uc3m.es/DrugDDI/DrugDDI.html)
* [Web named entities](http://nlp.uned.es/weps/weps-3/data)
* [Twitter sequence prediction tasks](http://www.cs.cmu.edu/~ark/TweetNLP/)
* [WNUT Emerging and Rare entity recognition shared task](http://noisy-text.github.io/2017/emerging-rare-entities.html)
* [Gun violence text data](http://gun-violence.org)

### Parsing

* [Universal Dependencies](http://universaldependencies.org)
* [WikiText](https://www.salesforce.com/products/einstein/ai-research/the-wikitext-dependency-language-modeling-dataset/)
* [Opinion mining](https://ikernels-portal.disi.unitn.it/projects/sentube/)

### Machine Translation

* [WMT 2018 Shared Task](http://www.statmt.org/wmt18/)
* [WMT 2017 Shared Task](http://www.statmt.org/wmt17/)
* [WMT 2016 Shared Task](http://www.statmt.org/wmt16/)
* [WMT 2015 Shared Task](http://www.statmt.org/wmt15/)
* [NMT 2018 Neural MT Shared Task](https://sites.google.com/site/wnmt18/shared-task)
* [Web Inventory of Transcribed and Translated Talks](https://wit3.fbk.eu/mt.php?release=2016-01)

### Unlabeled Data for Clustering, Language Models, etc.

* [Wikipedia XML data](http://www-connex.lip6.fr/%7Edenoyer/wikipediaXML/)
* [Web data](http://corpus.leeds.ac.uk/internet.html)
* [BootCat](http://bootcat.dipintra.it)

### Sentiment and Opinion Mining

* [Stanford Sentiment Treebank](https://nlp.stanford.edu/sentiment/treebank.html)
* [Movie reviews](http://ai.stanford.edu/~amaas/data/sentiment/)
* [Yelp Challenge](https://www.yelp.com/dataset/challenge)
* [Sentiment and opinion mining datasets](https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html)

### Natural Language Understanding and Inference

* [GLUE Benchmark](https://gluebenchmark.com)
* [RepEval 2017](https://repeval2017.github.io/shared/)
* [The Stanford Natural Language Inference (SNLI) Corpus](https://nlp.stanford.edu/projects/snli/)
* [Multi-Genre NLI](https://www.nyu.edu/projects/bowman/multinli/)
* [MedNLI](https://physionet.org/physiotools/mimic-code/mednli/)
* [XNLI](https://www.nyu.edu/projects/bowman/xnli/)

### Question Answering

* [Qanta shared task](https://sites.google.com/view/qanta/home) 
* [Algebra Question Answering with Rationales](https://github.com/deepmind/AQuA/)
* [Quora Question Pairs](https://www.kaggle.com/c/quora-question-pairs).
* Reverse QA: Jeopardy style QA. [json](https://drive.google.com/file/d/0BwT5wj_P7BKXb2hfM3d2RHU1ckE/view) and [csv](https://drive.google.com/file/d/0BwT5wj_P7BKXUl9tOUJWYzVvUjA/view)
* [CoQA](https://stanfordnlp.github.io/coqa/)
* [SQuAD](https://rajpurkar.github.io/SQuAD-explorer/)
* [HotpotQA](https://hotpotqa.github.io/)

## Project Submission

### Project title and abstract (due on {{ site.hwdates[5].abstract }})

For your project, please submit a Title and an Abstract (in Markdown format)
that describes what topic/problem your group will work on, the scope of the project 
and the data you plan to use.
The title/abstract is not graded, but you will receive feedback on the feasibility of the project. 

To submit, go to [Coursys]({{ site.coursys }}). Under the `Project Abstract`
activity, enter your Title and Abstract in Markdown
format. Your abstract should
be about 250 words (please definitely use less than 1000 words).

### Project proposal (due on {{ site.hwdates[5].proposal }})

For your project proposal please submit a PDF file that describes
what problem you plan to work on, what data you will use, and the basic approach you plan to take.

The project proposal PDF should be 1-2 pages in the style of a conference (e.g. ACL/EMNLP) submission.  Your project milestone and final report should use the same template.  Links to acceptable templates are below:
* [ACL style download](http://acl2020.org/downloads/acl2020-templates.zip)
* [ACL style template Overleaf](https://www.overleaf.com/latex/templates/acl-2020-proceedings-template/zsrkcwjptpcd)
* [EMNLP style download](https://2020.emnlp.org/files/emnlp2020-templates.zip)
* [EMNLP style template Overleaf](https://www.overleaf.com/latex/templates/emnlp-2020/knvtcxwzhbbz)

Make sure the following points are in your proposal.

* Motivation 
    * which NLP task do you plan to do; 
    * which aspect of the problem / task did your group plan to work on (accuracy, interpretability, etc.); 
    * provide some reasons for your choice
* Approach 
    * Describe the algorithms and machine learning models you plan to use in your project. 
    * Using equations is not necessary but if you do, use a clear mathematical style to explain your model(s).
* Data
    * Exactly which data set do you plan to use
* Evaluation
    * What is the evaluation measure for the data set and what is the baseline
* Timeline and work breakdown
    * What do you plan to achieve by the milestone?  
    * How will the work be allocated between the team members?

Go to [Coursys]({{ site.coursys }}). Under the `Project Proposal`
activity submit the following files:

* `proposal.pdf`: this is the project proposal report


### Project milestone (due on {{ site.hwdates[5].milestone }})

For your project milestone please submit a PDF file that describes
progress you made so far on your project and plans for the remainder.
For the final write-up you will need to also submit your code, so we encourage
to get started early and submit preliminary code and results with the milestone.

The project milestone PDF should be 2-4 pages in the style of a conference (e.g. ACL/EMNLP) submission.  Your final report should use the same template.  Links to acceptable templates are below:
* [ACL style download](http://acl2020.org/downloads/acl2020-templates.zip)
* [ACL style template Overleaf](https://www.overleaf.com/latex/templates/acl-2020-proceedings-template/zsrkcwjptpcd)
* [EMNLP style download](https://2020.emnlp.org/files/emnlp2020-templates.zip)
* [EMNLP style template Overleaf](https://www.overleaf.com/latex/templates/emnlp-2020/knvtcxwzhbbz)

Make sure the following points are covered.
* Progress
    * What have you achieved so far?
    * Are there any issues you encountered?
* Plans
    * What are the remaining steps?
    * Do you have any plans for addressing challenges or issues?
* Data
    * What did you find out about the data so far?
* Results
    * Summary of preliminary results
    * Remaining results that you plan to produce

A good structure for the milestone report will include the following sections.  It can then also serve as a draft for your final project write-up.
* Introduction 
    * Motivate the problem, describe your goals, and highlight your findings (if you have findings)
* Approach 
    * Provide details on your main approach and baselines.  Be specific.  Make clear what part is original, what code you are writing yourself, what code you are using that is taken from elsewhere (homework, github, etc)
* Experiments 
    * Describe the **dataset** (provide some information about the data such as statistics and analysis).
    * Describe the **evaluation metrics** you will be using. 
    * Describe what experiments you plan to run and/or any results you have so far.  
    * Also provide training details, training times, etc. (if you have preliminary experiements) 
* Future Work 
    * What is your plan for the rest of the project?  
* Reference - provide references using BibTex 

Grading of the milestone will be based on the progress and the quality of writing.  

Go to [Coursys]({{ site.coursys }}). Under the `Project Milestone`
activity submit the following files:

* `milestone.pdf`: this is the project milestone report

Optionally, you can also upload `source.zip` and `output.zip` for your project.  These will not be graded.


### Project Write-up (due on {{ site.hwdates[5].deadline }})

You must submit your project write-up as a PDF document.
In addition you must submit a Python notebook `project.ipynb` and your source
code for your project in your GitLab repository:

    git@csil-git1.cs.surrey.sfu.ca:USER/nlpclass-{{ site.semcode }}-g-GROUP.git

Put all your project files into the directory `project` in your
GitLab repository.

Make sure you have a `requirements.txt` file for your project 
so that we can use a virtual environment to run your code.

Your Python notebook must be called `project.ipynb`. 

In addition to writing code for a good project submission, the description of
what you did for your project as a PDF report is also a very important 
part of your project submission. The PDF writeup should have
the following sections and **must** cover the following information:

* Introduction 
    * Which aspect of the problem / task did your group choose to improve and reasons for your choice.
* Approach 
    * Describe the algorithms and machine learning models used in your project. Use clear mathematical notation and diagrams to explain your model(s).
* Experiments 
    * Data - What data was used? how was it used? Is there anything interesting about the data?
    * Implementation - What code did you use? Did you implement everything by yourself?  If you used homework code, which homework code you used in your project. Provide exactly which code was used in your project not written by your group (e.g. use of an aligner from an open-source project).
    * Evaluation: Describe what kind of evaluation you are doing, what metrics you are using
    * Methods being compared: which methods you are comparing against each other?
    * Results: Include a detailed comparison of different method and analysis of the results.  Did you improve over the baseline. Why or why not?
* Conclusion
    * What did you learn from your experiments?
    * What could be fixed in your approach. 
    * What you did not have time to finish, but you think would be a useful addition to your project.
* References
    * Provide references using BibTex

Please read this [guide to presenting your work](assets/cached/cs224u/cs224u-2019-presenting.pdf). Also available is a [video tutorial covering the same material](https://www.youtube.com/watch?v=WXLb4h2A724).

### Submit your project on Coursys

Go to [Coursys]({{ site.coursys }}). Under the `Final Project`
activity submit the following zip files:

* `report.pdf`: this is the final project report
* `source.zip`: this zip file should contain your iPython notebook and only the source code you have written (along with a requirements.txt for a virtualenv). Do not include any data files in this zipfile. Please also include a README.username file as you have done for all your homeworks in this zip file.
* `output.zip`: output of your project implementation on a dataset. please include the evaluation code and references to allow us to check the evaluation you present in your write-up. Note this should only be your output on the test data file of some dataset plus any evaluation code and clear instructions on how to run the evaluation script.

The instructions for submission and development are provided in more detail in [Homework 0](hw0.html).

There are **no grace days** for project submission! So submit early and often.

That's it. You are done with your Final Project!

## Grading of Final Project Work

The final projects for this course will be graded using the following criteria:

* Originality 
* Substance (amount of work done for the project)
* Well documented use of prior results from research papers
* Clarity of the writing, code and documentaiton quality
* Quality of experimental design
* Quality of evaluation and results
* Theoretical insights / Practical insights
* Group work (did the group work effectively together)
* Overall score (based on the above criteria, but can include other factors like overall polish or creativity)

## Project Grading Framework

The total marks are distributed as follows:

* Work. Work done in the project. Results obtained. 50 marks (see the section on _Grading of the Final Project Work_ for grading details) 
* Report. Description and analysis of what was done. 25 marks (see the section on _Project Write-up_ for grading details)
* Poster. Performance at the online poster session and presentation quality. 25 marks (details TBD)
* Milestone. Description of progress and project plans. 20 marks (see the section on _Milestone_ for grading details)

